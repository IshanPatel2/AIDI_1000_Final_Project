{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Text Classification Algorithms: A Survey</center>\n",
    "\n",
    "###### <center>Kamran Kowsari, Kiana Jafari Meimandi, Mojtaba Heidarysafa, Sanjana Mendu, Laura Barnes and Donald Brown.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Convolutional Neural Networks:</center>\n",
    "\n",
    "#### A deep learning architecture called a convolutional neural network (CNN) is intended for the analysis of spatial and visual data. Convolutional and pooling layers, for example, are used to automatically learn hierarchical features from incoming data. CNNs may successfully complete tasks like image classification, object recognition, and segmentation thanks to these layers' ability to properly collect patterns and edges inside images. By eliminating the need for manual feature engineering and making it possible to recognize intricate patterns in images, CNNs have completely changed computer vision. Modern AI applications rely heavily on them because of their capacity to effectively manage big datasets and keep spatial links.\n",
    "\n",
    "#### Research paper Link: <a href = \"https://arxiv.org/pdf/1904.08067v5.pdf\">Click Here</a>\n",
    "\n",
    "#### Dataset source link: <a href = \"https://github.com/kk7nc/Text_Classification/tree/master/Data\">Click Here</a>\n",
    "\n",
    "#### Github Link: <a href = \"https://github.com/kk7nc/Text_Classification/tree/master/code\">Click Here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WOXLG2bjQho",
    "outputId": "2289266a-dd1e-492d-9611-0e95a808d918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=8, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Copyright (C) 2018  Kamran Kowsari <kk7nc@virginia.edu>\n",
    " * Last Update: 04/25/2018\n",
    " * This file is part of  RMDL project, University of Virginia.\n",
    " * Free to use, change, share and distribute source code of RMDL\n",
    " * Refrenced paper : RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Refrenced paper : An Improvement of Data Classification using Random Multimodel Deep Learning (RMDL)\n",
    " * Comments and Error: email: kk7nc@virginia.edu\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\Glove'\n",
    "\n",
    "# url of the binary data\n",
    "\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract(data='Wikipedia'):\n",
    "    \"\"\"\n",
    "    Download and extract the GloVe\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if data=='Wikipedia':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    elif data=='Common_Crawl_840B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip'\n",
    "    elif data=='Common_Crawl_42B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip'\n",
    "    elif data=='Twitter':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip'\n",
    "    else:\n",
    "        print(\"prameter should be Twitter, Common_Crawl_42B, Common_Crawl_840B, or Wikipedia\")\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    print(filepath)\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath)#, reporthook=_progress)\n",
    "\n",
    "\n",
    "        zip_ref = zipfile.ZipFile(filepath, 'r')\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "        zip_ref.close()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6hqA2SHjXjj",
    "outputId": "0f9db0e7-1560-489f-c4c1-ddb8c8006564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=8, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Copyright (C) 2018  Kamran Kowsari <kk7nc@virginia.edu>\n",
    " * Last Update: 04/25/2018\n",
    " * This file is part of  RMDL project, University of Virginia.\n",
    " * Free to use, change, share and distribute source code of RMDL\n",
    " * Refrenced paper : RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Refrenced paper : An Improvement of Data Classification using Random Multimodel Deep Learning (RMDL)\n",
    " * Comments and Error: email: kk7nc@virginia.edu\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\data_WOS'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'http://kowsari.net/WebOfScience.tar.gz'\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the WOS datasets\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "\n",
    "        print('Downloaded', filename)\n",
    "\n",
    "        tarfile.open(filepath, 'r').extractall(dest_directory)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0aESNAEjfPM",
    "outputId": "7de0e79f-5bf2-4df4-9e8f-fce464917ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: RMDL in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (1.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (1.6.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (2.7.0)\n",
      "Requirement already satisfied: keras>=2.0.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (0.24.1)\n",
      "Requirement already satisfied: nltk>=3.2.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from RMDL) (3.6.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->RMDL) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->RMDL) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->RMDL) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->RMDL) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->RMDL) (2.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.2.4->RMDL) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.2.4->RMDL) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.2.4->RMDL) (2021.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.2.4->RMDL) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>=0.22.0->RMDL) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.0->RMDL) (2.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (0.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (12.0.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (3.19.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (3.7.4.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (0.40.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.12.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (0.22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow->RMDL) (1.41.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (3.3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow->RMDL) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm->nltk>=3.2.4->RMDL) (0.4.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->RMDL) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->RMDL) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->RMDL) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->RMDL) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>='4.4' in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->RMDL) (3.10.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->RMDL) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->RMDL) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->RMDL) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->RMDL) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from importlib-metadata>='4.4'->markdown>=2.6.8->tensorboard~=2.6->tensorflow->RMDL) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->RMDL) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->RMDL) (3.1.1)\n",
      "Requirement already satisfied: Keras-Preprocessing in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.20.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install RMDL\n",
    "!pip install Keras-Preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, AveragePooling2D, Conv2D,Reshape\n",
    "from keras.models import Sequential,Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.utils import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n",
    "    np.random.seed(7)\n",
    "    text = np.concatenate((X_train, X_test), axis=0)\n",
    "    text = np.array(text)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_train = text[0:len(X_train), ]\n",
    "    X_test = text[len(X_train):, ]\n",
    "    embeddings_index = {}\n",
    "    f = open(r\"C:\\Users\\ASUS\\Downloads\\glove.6B\\glove.6B.100d.txt\", encoding=\"utf8\") ## GloVe file which could be download https://nlp.stanford.edu/projects/glove/\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_train, X_test, word_index,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model_CNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=100, dropout=0.5):\n",
    "\n",
    "    \"\"\"\n",
    "        def buildModel_CNN(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
    "        word_index in word index ,\n",
    "        embeddings_index is embeddings index, look at data_helper.py\n",
    "        nClasses is number of classes,\n",
    "        MAX_SEQUENCE_LENGTH is maximum lenght of text sequences,\n",
    "        EMBEDDING_DIM is an int value for dimention of word embedding look at data_helper.py\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
    "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
    "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
    "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
    "                exit(1)\n",
    "\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "\n",
    "    # applying a more complex convolutional approach\n",
    "    convs = []\n",
    "    filter_sizes = []\n",
    "    layer = 5\n",
    "    print(\"Filter  \",layer)\n",
    "    for fl in range(0,layer):\n",
    "        filter_sizes.append((fl+2,fl+2))\n",
    "\n",
    "    node = 128\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    emb = Reshape((500,10, 10), input_shape=(500,100))(embedded_sequences)\n",
    "\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv2D(node, padding=\"same\", kernel_size=fsz, activation='relu')(emb)\n",
    "        l_pool = AveragePooling2D(pool_size=(5,1), padding=\"same\")(l_conv)\n",
    "        #l_pool = Dropout(0.25)(l_pool)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "    l_cov1 = Conv2D(node, (5,5), padding=\"same\", activation='relu')(l_merge)\n",
    "    l_cov1 = AveragePooling2D(pool_size=(5,2), padding=\"same\")(l_cov1)\n",
    "    l_cov2 = Conv2D(node, (5,5), padding=\"same\", activation='relu')(l_cov1)\n",
    "    l_pool2 = AveragePooling2D(pool_size=(5,2), padding=\"same\")(l_cov2)\n",
    "    l_cov2 = Dropout(dropout)(l_pool2)\n",
    "    l_flat = Flatten()(l_cov2)\n",
    "    l_dense = Dense(12, activation='relu')(l_flat)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "\n",
    "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
    "    model = Model(sequence_input, preds)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\",\n",
       " 'From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n',\n",
       " 'From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It\\'s got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek\\'s address/phone number?  I\\'d like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n',\n",
       " 'From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\\nSubject: Re: Shuttle Launch Question\\nOrganization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\\nDistribution: sci\\nLines: 23\\n\\nFrom article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\\n>>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\\n>>>\"Clear caution & warning memory.  Verify no unexpected\\n>>>errors. ...\".  I am wondering what an \"expected error\" might\\n>>>be.  Sorry if this is a really dumb question, but\\n> \\n> Parity errors in memory or previously known conditions that were waivered.\\n>    \"Yes that is an error, but we already knew about it\"\\n> I\\'d be curious as to what the real meaning of the quote is.\\n> \\n> tom\\n\\n\\nMy understanding is that the \\'expected errors\\' are basically\\nknown bugs in the warning system software - things are checked\\nthat don\\'t have the right values in yet because they aren\\'t\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n\\'ok, if you see a warning no. 213 before liftoff, ignore it\\'.\\n\\n - Jonathan\\n\\n\\n',\n",
       " 'From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\nSubject: Re: Rewording the Second Amendment (ideas)\\nOrganization: VTT\\nLines: 58\\n\\nIn article <1r1eu1$4t@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\\n>In article <1993Apr20.083057.16899@ousrvr.oulu.fi>, dfo@vttoulu.tko.vtt.fi (Foxvog Douglas) writes:\\n>> In article <1qv87v$4j3@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\\n>> >In article <C5n3GI.F8F@ulowell.ulowell.edu>, jrutledg@cs.ulowell.edu (John Lawrence Rutledge) writes:\\n>\\n>> >> The massive destructive power of many modern weapons, makes the\\n>> >> cost of an accidental or crimial usage of these weapons to great.\\n>> >> The weapons of mass destruction need to be in the control of\\n>> >> the government only.  Individual access would result in the\\n>> >> needless deaths of millions.  This makes the right of the people\\n>> >> to keep and bear many modern weapons non-existant.\\n\\n>> >Thanks for stating where you\\'re coming from.  Needless to say, I\\n>> >disagree on every count.\\n\\n>> You believe that individuals should have the right to own weapons of\\n>> mass destruction?  I find it hard to believe that you would support a \\n>> neighbor\\'s right to keep nuclear weapons, biological weapons, and nerve\\n>> gas on his/her property.  \\n\\n>> If we cannot even agree on keeping weapons of mass destruction out of\\n>> the hands of individuals, can there be any hope for us?\\n\\n>I don\\'t sign any blank checks.\\n\\nOf course.  The term must be rigidly defined in any bill.\\n\\n>When Doug Foxvog says \"weapons of mass destruction,\" he means CBW and\\n>nukes.  When Sarah Brady says \"weapons of mass destruction\" she means\\n>Street Sweeper shotguns and semi-automatic SKS rifles.  \\n\\nI doubt she uses this term for that.  You are using a quote allegedly\\nfrom her, can you back it up?\\n\\n>When John\\n>Lawrence Rutledge says \"weapons of mass destruction,\" and then immediately\\n>follows it with:\\n\\n>>> The US has thousands of people killed each year by handguns,\\n>>> this number can easily be reduced by putting reasonable restrictions\\n>>> on them.\\n\\n>...what does Rutledge mean by the term?\\n\\nI read the article as presenting first an argument about weapons of mass\\ndestruction (as commonly understood) and then switching to other topics.\\nThe first point evidently was to show that not all weapons should be\\nallowed, and then the later analysis was, given this understanding, to\\nconsider another class.\\n\\n>cdt@rocket.sw.stratus.com   --If you believe that I speak for my company,\\n>OR cdt@vos.stratus.com        write today for my special Investors\\' Packet...\\n\\n\\n\\n-- \\ndoug foxvog\\ndouglas.foxvog@vtt.fi\\n',\n",
       " 'From: bmdelane@quads.uchicago.edu (brian manning delaney)\\nSubject: Brain Tumor Treatment (thanks)\\nReply-To: bmdelane@midway.uchicago.edu\\nOrganization: University of Chicago\\nLines: 12\\n\\nThere were a few people who responded to my request for info on\\ntreatment for astrocytomas through email, whom I couldn\\'t thank\\ndirectly because of mail-bouncing probs (Sean, Debra, and Sharon).  So\\nI thought I\\'d publicly thank everyone.\\n\\nThanks! \\n\\n(I\\'m sure glad I accidentally hit \"rn\" instead of \"rm\" when I was\\ntrying to delete a file last September. \"Hmmm... \\'News?\\' What\\'s\\nthis?\"....)\\n\\n-Brian\\n',\n",
       " 'From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: Re: IDE vs SCSI\\nOrganization: New Mexico State University, Las Cruces, NM\\nLines: 44\\nDistribution: world\\nNNTP-Posting-Host: dante.nmsu.edu\\n\\nDXB132@psuvm.psu.edu writes:\\n>In article <1qlbrlINN7rk@dns1.NMSU.Edu>, bgrubb@dante.nmsu.edu (GRUBB) says:\\n>>In PC Magazine April 27, 1993:29 \"Although SCSI is twice as fasst as ESDI,\\n>>20% faster than IDE, and support up to 7 devices its acceptance ...has   \\n>>long been stalled by incompatability problems and installation headaches.\"\\n                                                                      \\n>I love it when magazine writers make stupid statements like that re:      \\n>performance. Where do they get those numbers? I\\'ll list the actual\\n>performance ranges, which should convince anyone that such a               \\n>statement is absurd:                                                     \\n>SCSI-I ranges from 0-5MB/s.                                                \\n>SCSI-II ranges from 0-40MB/s.            \\n>IDE ranges from 0-8.3MB/s.                          \\n>ESDI is always 1.25MB/s (although there are some non-standard versions)\\nALL this shows is that YOU don\\'t know much about SCSI.\\n\\nSCSI-1 {with a SCSI-1 controler chip} range is indeed 0-5MB/s\\nand that is ALL you have right about SCSI\\nSCSI-1 {With a SCSI-2 controller chip}: 4-6MB/s with 10MB/s burst {8-bit}\\n Note the INCREASE in SPEED, the Mac Quadra uses this version of SCSI-1\\n so it DOES exist. Some PC use this set up too.\\nSCSI-2 {8-bit/SCSI-1 mode}:          4-6MB/s with 10MB/s burst\\nSCSI-2 {16-bit/wide or fast mode}:  8-12MB/s with 20MB/s burst\\nSCSI-2 {32-bit/wide AND fast}:     15-20MB/s with 40MB/s burst\\n \\nBy your OWN data the \"Although SCSI is twice as fast as ESDI\" is correct\\nWith a SCSI-2 controller chip SCSI-1 can reach 10MB/s which is indeed\\n\"20% faster than IDE\" {120% of 8.3 is 9.96}. ALL these SCSI facts have been\\nposted to this newsgroup in my Mac & IBM info sheet {available by FTP on \\nsumex-aim.stanford.edu (36.44.0.6) in the info-mac/report as \\nmac-ibm-compare[version #].txt (It should be 173 but 161 may still be there)}\\n\\nPart of this problem is both Mac and IBM PC are inconsiant about what SCSI\\nis which.  Though it is WELL documented that the Quadra has a SCSI-2 chip\\nan Apple salesperson said \"it uses a fast SCSI-1 chip\" {Not at a 6MB/s,\\n10MB/s burst it does not. SCSI-1 is 5MB/s maximum synchronous and Quadra\\nuses ANsynchronous SCSI which is SLOWER}  It seems that Mac and IBM see\\nSCSI-1 interface and think \\'SCSI-1\\' when it maybe a SCSI-1 interface driven\\nin the machine by a SCSi-2 controller chip in 8-bit mode {Which is MUCH\\nFASTER then true SCSI-1 can go}.\\n\\nDon\\'t slam an article because you don\\'t understand what is going on.\\nOne reference for the Quadra\\'s SCSI-2 controller chip is \\n(Digital Review, Oct 21, 1991 v8 n33 p8(1)).\\n',\n",
       " 'From: holmes7000@iscsvax.uni.edu\\nSubject: WIn 3.0 ICON HELP PLEASE!\\nOrganization: University of Northern Iowa\\nLines: 10\\n\\nI have win 3.0 and downloaded several icons and BMP\\'s but I can\\'t figure out\\nhow to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\\n\\n\\nThanx,\\n\\n-Brando\\n\\nPS Please E-mail me\\n\\n',\n",
       " \"From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubject: Re: Sigma Designs Double up??\\nArticle-I.D.: ux1.C52u8x.B62\\nOrganization: University of Illinois at Urbana\\nLines: 29\\n\\njap10@po.CWRU.Edu (Joseph A. Pellettiere) writes:\\n\\n\\n>\\tI am looking for any information about the Sigma Designs\\n>\\tdouble up board.  All I can figure out is that it is a\\n>\\thardware compression board that works with AutoDoubler, but\\n>\\tI am not sure about this.  Also how much would one cost?\\n\\nI've had the board for over a year, and it does work with Diskdoubler,\\nbut not with Autodoubler, due to a licensing problem with Stac Technologies,\\nthe owners of the board's compression technology. (I'm writing this\\nfrom memory; I've lost the reference. Please correct me if I'm wrong.)\\n\\nUsing the board, I've had problems with file icons being lost, but it's\\nhard to say whether it's the board's fault or something else; however,\\nif I decompress the troubled file and recompress it without the board,\\nthe icon usually reappears. Because of the above mentioned licensing\\nproblem, the freeware expansion utility DD Expand will not decompress\\na board-compressed file unless you have the board installed.\\n\\nSince Stac has its own product now, it seems unlikely that the holes\\nin Autodoubler/Diskdoubler related to the board will be fixed.\\nWhich is sad, and makes me very reluctant to buy Stac's product since\\nthey're being so stinky. (But hey, that's competition.)\\n-- \\n\\nStan Kerr    \\nComputing & Communications Services Office, U of Illinois/Urbana\\nPhone: 217-333-5217  Email: stankerr@uiuc.edu   \\n\",\n",
       " 'From: irwin@cmptrc.lonestar.org (Irwin Arnstein)\\nSubject: Re: Recommendation on Duc\\nSummary: What\\'s it worth?\\nDistribution: usa\\nExpires: Sat, 1 May 1993 05:00:00 GMT\\nOrganization: CompuTrac Inc., Richardson TX\\nKeywords: Ducati, GTS, How much? \\nLines: 13\\n\\nI have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\\nvery well, paint is the bronze/brown/orange faded out, leaks a bit of oil\\nand pops out of 1st with hard accel.  The shop will fix trans and oil \\nleak.  They sold the bike to the 1 and only owner.  They want $3495, and\\nI am thinking more like $3K.  Any opinions out there?  Please email me.\\nThanks.  It would be a nice stable mate to the Beemer.  Then I\\'ll get\\na jap bike and call myself Axis Motors!\\n\\n-- \\n-----------------------------------------------------------------------\\n\"Tuba\" (Irwin)      \"I honk therefore I am\"     CompuTrac-Richardson,Tx\\nirwin@cmptrc.lonestar.org    DoD #0826          (R75/6)\\n-----------------------------------------------------------------------\\n',\n",
       " 'From: david@terminus.ericsson.se (David Bold)\\nSubject: Re: Question for those with popular morality\\nReply-To: david@terminus.ericsson.se\\nDistribution: world\\nOrganization: Camtec Electronics (Ericsson), Leicester, England\\nLines: 77\\nNntp-Posting-Host: bangkok\\n\\nIn article 17570@freenet.carleton.ca, ad354@Freenet.carleton.ca (James Owens) writes:\\n>\\n>In a previous article, david@terminus.ericsson.se (David Bold) says:\\n>\\n>>\\n>>I don\\'t mean to be rude, but I think that you\\'ve got hold of the wrong\\n>>end of a different stick...\\n>>\\n>>David\\n>\\n>I had a look at your posting again and I see what you mean!  I was so\\n>intent on explaining how Jung thought we could be more moral than God that\\n>I overlooked your main line of thought.\\n>\\n>You seem to be saying that, God being unknowable, His morality is unknowable.\\n\\nYep, that\\'s pretty much it. I\\'m not a Jew but I understand that this is the\\nJewish way of thinking. However, the Jews believe that the Covenant between\\nYHWH and the Patriarchs (Abraham and Moses, in this case) establishes a Moral\\nCode to follow for mankind. Even the Jews could not decide where the boundaries\\nfall, though.\\n\\nAs I understand it, the Sadducees believed that the Torah was all that was\\nrequired, whereas the Pharisees (the ancestors of modern Judaism) believed that\\nthe Torah was available for interpretation to lead to an understanding of\\nthe required Morality in all its nuances (->Talmud).\\n\\nThe essence of all of this is that Biblical Morality is an interface between\\nMan and YHWH (for a Jew or Christian) and does not necessarily indicate\\nanything about YHWH outside of that relationship (although one can speculate).\\n\\n>\\n>The first thing that comes to mind is that man is supposed to be created\\n>in His image, so there is an argument that we are committed to whatever\\n>moral code He follows as part of trying to live up to that image.  If we\\n>are supposed to live by Christ\\'s example, you would be hard pressed to\\n>argue that God is a \"do what I say, not what I do\" kind of guy.\\n\\nThe trouble with all of this is that we don\\'t really know what the \"created\\nin His image\" means. I\\'ve heard a number of different opinions on this and\\nhave still not come to any conclusion. This rather upsets the Apple Cart if\\none wants to base a Life Script on this shaky foundation (to mix metaphors\\nunashamedly!) As to living by Christ\\'s example, we know very little about\\nJesus as a person. We only have his recorded utterances in a set of narratives\\nby his followers, and some very small references from comtemporary historians.\\nRevelation aside, one can only \"know\" Christ second-hand or worse.\\n\\nThis is not an attempt to debunk Christianity (although it may seem that way\\ninitially), the point I`m trying to make is that we only really have the Bible\\nto interpret, and that interpretation is by humanity. I guess this is where\\nFaith or Relevation comes in with all its inherent subjectiveness.\\n\\n>\\n>Metaphysically, if there are multiple moral codes then there is no\\n>Absolute moral code, and I think this is theologically questionable.\\n\\nNo. There may be an absolute moral code. There are undoubtably multiple\\nmoral codes. The multiple moral codes may be founded in the absolute moral\\ncode. As an example, a parent may tell a child never to swear, and the child\\nmay assume that the parent never swears simply because the parent has told\\nthe child that it is \"wrong\". Now, the parent may swear like a trooper in\\nthe pub or bar (where there are no children). The \"wrongness\" here is if\\nthe child disobeys the parent. The parent may feel that it is \"inappropriate\"\\nto swear in front of children but may be quite happy to swear in front of\\nanimals. The analogy does not quite hold water because the child knows that\\nhe is of the same type as the parent (and may be a parent later in life) but\\nyou get the gist of it? Incidentally, the young child considers the directive\\nas absolute until he gets older (see Piaget) and learns a morality of his own.\\n\\nDavid.\\n\\n---\\nOn religion:\\n\\n\"Oh, where is the sea?\", the fishes cried,\\nAs they swam its clearness through.\\n\\n',\n",
       " 'From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: *$G4qxF,fekVH6\\nNntp-Posting-Host: hpfcmrc.fc.hp.com\\nOrganization: Hewlett Packard, Fort Collins, CO\\nX-Newsreader: TIN [version 1.1 PL8.5]\\nLines: 15\\n\\n\\n\\n--\\n\\n\\nRegards,\\nRod Cerkoney\\n                                                        /\\\\\\n______________________________________________         /~~\\\\\\n                                                      /    \\\\\\n  Rod Cerkoney MS 37     email:                      /      \\\\ \\n  Hewlett Packard         rodc@fc.hp.com        /\\\\  /        \\\\  \\n  3404 East Harmony Rd.  Hpdesk:               /  \\\\/          \\\\    /\\\\\\n  Fort Collins, CO 80525  HP4000/UX           /    \\\\           \\\\  /  \\\\\\n_____________________________________________/      \\\\           \\\\/    \\\\__\\n',\n",
       " 'From: dbm0000@tm0006.lerc.nasa.gov (David B. Mckissock)\\nSubject: Re: Space Station Redesign, JSC Alternative #4\\nOrganization: NASA Lewis Research Center / Cleveland, Ohio\\nLines: 102\\nDistribution: world\\nNNTP-Posting-Host: tm0006.lerc.nasa.gov\\nNews-Software: VAX/VMS VNEWS 1.41    \\n\\nIn article <1993Apr23.184732.1105@aio.jsc.nasa.gov>, kjenks@gothamcity.jsc.nasa.gov writes...\\n\\n   {Description of \"External Tank\" option for SSF redesign deleted}\\n\\n>Mark proposed this design at Joe Shea\\'s committee in Crystal City,\\n>and he reports that he was warmly received.  However, the rumors\\n>I hear say that a design based on a wingless Space Shuttle Orbiter\\n>seems more likely.\\n\\nYo Ken, let\\'s keep on-top of things! Both the \"External Tank\" and\\n\"Wingless Orbiter\" options have been deleted from the SSF redesign\\noptions list. Today\\'s (4/23) edition of the New York Times reports\\nthat O\\'Connor told the panel that some redesign proposals have\\nbeen dropped, such as using the \"giant external fuel tanks used\\nin launching space shuttles,\" and building a \"station around\\nan existing space shuttle with its wings and tail removed.\"\\n\\nCurrently, there are three options being considered, as presented\\nto the advisory panel meeting yesterday (and as reported in\\ntoday\\'s Times).\\n\\nOption \"A\" - Low Cost Modular Approach\\nThis option is being studied by a team from MSFC. {As an aside,\\nthere are SSF redesign teams at MSFC, JSC, and LaRC supporting\\nthe SRT (Station Redesign Team) in Crystal City. Both LeRC and\\nReston folks are also on-site at these locations, helping the respective\\nteams with their redesign activities.} Key features of this\\noption are:\\n  -  Uses \"Bus-1\", a modular bus developed by Lockheed that\\'s\\n     qualified for STS and ELV\\'s. The bus provides propulsion, GN&C\\n     Communications, & Data Management. Lockheed developed this\\n     for the Air Force.\\n  -  A \"Power Station Capability\" is obtained in 3 Shuttle Flights.\\n     SSF Solar arrays are used to provide 20 kW of power. The vehicle\\n     flies in an \"arrow mode\" to optimize the microgravity environment.\\n     Shuttle/Spacelab missions would utilize the vehilce as a power\\n     source for 30 day missions.\\n  -  Human tended capability (as opposed to the old SSF sexist term\\n     of man-tended capability) is achieved by the addition of the\\n     US Common module. This is a modified version of the existing\\n     SSF Lab module (docking ports are added for the International\\n     Partners\\' labs, taking the place of the nodes on SSF). The\\n     Shuttle can be docked to the station for 60 day missions.\\n     The Orbiter would provide crew habitability & EVA capability.\\n  -  International Human Tended. Add the NASDA & ESA modules, and\\n     add another 20 kW of power\\n  -  Permanent Human Presence Capability. Add a 3rd power module,\\n     the U.S. habitation module, and an ACRV (Assured Crew Return\\n     Vehicle).\\n\\nOption \"B\" - Space Station Freedom Derived\\nThe Option \"B\" team is based at LaRC, and is lead by Mike Griffin.\\nThis option looks alot like the existing SSF design, which we\\nhave all come to know and love :)\\n\\nThis option assumes a lightweight external tank is available for\\nuse on all SSF assembly flights (so does option \"A\"). Also, the \\nnumber of flights is computed for a 51.6 inclination orbit,\\nfor both options \"A\" and \"B\".\\n\\nThe build-up occurs in six phases:\\n  -  Initial Research Capability reached after 3 flights. Power\\n     is transferred from the vehicle to the Orbiter/Spacelab, when\\n     it visits.\\n  -  Man-Tended Capability (Griffin has not yet adopted non-sexist\\n     language) is achieved after 8 flights. The U.S. Lab is\\n     deployed, and 1 solar power module provides 20 kW of power.\\n  -  Permanent Human Presence Capability occurs after 10 flights, by\\n     keeping one Orbiter on-orbit to use as an ACRV (so sometimes\\n     there would be two Orbiters on-orbit - the ACRV, and the\\n     second one that comes up for Logistics & Re-supply).\\n  -  A \"Two Fault Tolerance Capability\" is achieved after 14 flights,\\n     with the addition of a 2nd power module, another thermal\\n     control system radiator, and more propulsion modules.\\n  -  After 20 flights, the Internationals are on-board. More power,\\n     the Habitation module, and an ACRV are added to finish the\\n     assembly in 24 flights.\\n\\nMost of the systems currently on SSF are used as-is in this option, \\nwith the exception of the data management system, which has major\\nchanges.\\n\\nOption C - Single Core Launch Station.\\nThis is the JSC lead option. Basically, you take a 23 ft diameter\\ncylinder that\\'s 92 ft long, slap 3 Space Shuttle Main Engines on\\nthe backside, put a nose cone on the top, attached it to a \\nregular shuttle external tank and a regular set of solid rocket\\nmotors, and launch the can. Some key features are:\\n  - Complete end-to-end ground integration and checkout\\n  - 4 tangentially mounted fixed solar panels\\n  - body mounted radiators (which adds protection against\\n    micrometeroid & orbital debris)\\n  - 2 centerline docking ports (one on each end)\\n  - 7 berthing ports\\n  - a single pressurized volume, approximately 26,000 cubic feet\\n    (twice the volume of skylab).\\n  - 7 floors, center passageway between floors\\n  - 10 kW of housekeeping power\\n  - graceful degradation with failures (8 power channels, 4 thermal\\n    loops, dual environmental control & life support system)\\n  - increased crew time for utilization\\n  - 1 micro-g thru out the core module\\n',\n",
       " \"From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nSubject: RE:  == MOVING SALE ===\\nSummary: RE:  === MOVING SALE ===\\nOrganization: UB\\nLines: 44\\nNntp-Posting-Host: lictor.acsu.buffalo.edu\\n\\nReduced Prices! \\nI have a list of things forsale on behalf of my brother, who's moving (moved\\nalready)\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tOffer:\\n1) Black and Decker Duster Plus (Portable Hand Vaccum)\\t\\n \\tpurchased for $32, \\t\\t\\t\\t\\t  $12\\n\\n2) SR-1000 Dual Cassette Portable Player, AM/FM\\n5-Band graphics Equalizer, high speed dubing, Duo \\nTape.Tape deck A, seems to have lost treble sound. \\nBut, I bet  it's fixable.\\n\\tpurchased for $80\\t\\t\\t\\t\\t  $25\\n\\n3)Monolux Zoom MicroScope, up to 1200X magnification\\nMade in Japan, includes case and accessories\\n\\tpurchased for $50\\t\\t\\t\\t\\t  $20\\n\\n4)Sunbeam 1400 Hair Dryer, the dryer you put your \\nhead under/into. You know, the ones you see in the salons.\\n(Don't ask me why my bro had it)\\n\\tpurchased for $60\\t\\t\\t\\t          $24\\n\\n5)Everylast Speed Bag, all leather. Brand new, never \\nused\\t\\t\\t\\t\\t\\t\\t\\t  $10\\n\\n6)Osterizer Pusle Matic Blender, with 10 speeds \\nand a cookbook, 5 years old\\t\\t\\t\\t\\t  $10\\n\\tpurchased for $50\\n\\n8)Binolux Binoculars . 7x35, extra wide angle\\n525ft. at 1000yds. with case. very new.\\t\\t                  $20\\n\\n9)Proctor and Silex Spray,Steam and Dry Iron.\\nvery new.\\t\\t\\t\\t\\t\\t\\t  $10\\n\\n\\nAny questions, contact me thru e-mail and I will reply expeditously\\nAnd always, S+H are not included, so please consider this.\\n\\nAnd lastly, I'm a very reasonable.Very Reasonable.\\n\\n\\t\\t\\t\\t\\tThanks,\\n\\t\\t\\t\\t\\t\\tJohn\\n\",\n",
       " 'From: mathew <mathew@mantis.co.uk>\\nSubject: Re: <Political Atheists?\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.01\\nLines: 22\\n\\nkmr4@po.CWRU.edu (Keith M. Ryan) writes:\\n> ( I am almost sure that Zyklon-B is immediate and painless method of \\n> death. If not, insert soem other form. )\\n> \\n>         And, ethnic and minority groups have been killed, mutilated and \\n> exterminated through out history, so I guess it was not unusual.\\n> \\n>         So, you would agree that the holocost would be allowed under the US \\n> Constitution?  [ in so far, the punishment. I doubt they recieved what would \\n> be considered a \"fair\" trial by US standards.\\n\\nDon\\'t be so sure.  Look what happened to Japanese citizens in the US during\\nWorld War II.  If you\\'re prepared to say \"Let\\'s round these people up and\\nstick them in a concentration camp without trial\", it\\'s only a short step to\\ngassing them without trial.  After all, it seems that the Nazis originally\\nonly intended to imprison the Jews; the Final Solution was dreamt up partly\\nbecause they couldn\\'t afford to run the camps because of the devastation\\ncaused by Goering\\'s Total War.  Those who weren\\'t gassed generally died of\\nmalnutrition or disease.\\n\\n\\nmathew\\n',\n",
       " 'From: ab@nova.cc.purdue.edu (Allen B)\\nSubject: Re: TIFF: philosophical significance of 42\\nOrganization: Purdue University\\nLines: 39\\n\\nIn article <prestonm.735400848@cs.man.ac.uk> prestonm@cs.man.ac.uk (Martin  \\nPreston) writes:\\n> Why not use the PD C library for reading/writing TIFF files? It took me a\\n> good 20 minutes to start using them in your own app.\\n\\nI certainly do use it whenever I have to do TIFF, and it usually works\\nvery well.  That\\'s not my point.  I\\'m >philosophically< opposed to it\\nbecause of its complexity.\\n\\nThis complexity has led to some programs\\' poor TIFF writers making\\nsome very bizarre files, other programs\\' inability to load TIFF\\nimages (though they\\'ll save them, of course), and a general\\ninability to interchange images between different environments\\ndespite the fact they all think they understand TIFF.\\n\\nAs the saying goes, \"It\\'s not me I\\'m worried about- it\\'s all the\\n>other<  assholes out there!\"  I\\'ve had big trouble with misuse and\\nabuse of TIFF over the years, and I chalk it all up to the immense (and\\nunnecessary) complexity of the format.\\n\\nIn the words of the TIFF 5.0 spec, Appendix G, page G-1 (capitalized\\nemphasis mine):\\n\\n\"The only problem with this sort of success is that TIFF was designed\\nto be powerful and flexible, at the expense of simplicity.  It takes a\\nfair amount of effort to handle all the options currently defined in\\nthis specification (PROBABLY NO APPLICATION DOES A COMPLETE JOB),\\nand that is currently the only way you can be >sure< that you will be\\nable to import any TIFF image, since there are so many\\nimage-generating applications out there now.\"\\n\\n\\nIf a program (or worse all applications) can\\'t read >every< TIFF\\nimage, that means there are some it won\\'t- some that I might have to\\ndeal with.  Why would I want my images to be trapped in that format?  I\\ndon\\'t and neither should anyone who agrees with my reasoning- not\\nthat anyone does, of course! :-)\\n\\nab\\n',\n",
       " 'From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nSubject: Insurance Rates on Performance Cars SUMMARY\\nOrganization: Louisiana Tech University\\nLines: 244\\nNNTP-Posting-Host: vm.cc.latech.edu\\nX-Newsreader: NNR/VM S_1.3.2\\n\\n     I recently posted an article asking what kind of rates single, male\\ndrivers under 25 yrs old were paying on performance cars. Here\\'s a summary of\\nthe replies I received.\\n \\n \\n \\n \\n-------------------------------------------------------------------------------\\n \\nI\\'m not under 25 anymore (but is 27 close enough).\\n \\n1992 Dodge Stealth RT/Twin Turbo (300hp model).\\nNo tickets, no accidents, own a house, have taken defensive driving 1,\\nairbag, abs, security alarm, single.\\n \\n$1500/year  $500 decut. State Farm Insurance (this includes the additional $100\\nfor the $1,000,000 umbrella policy over my car and house)  The base\\npolicy is the standard $100,000 - $100,000 - $300,000 policy required in DE.\\n \\nAfter 2nd defensive driving course it will be 5% less.\\n \\nI bought the car in September 1992.  The company I was with (never had\\nand accident or ticket in 11 years) quoted me $2,500.\\n \\nHope this helps.\\n \\nSteve Flynn\\nUniversity of Delaware\\n======================================================================== 45\\n \\n    Kevin:\\n \\n    (Hope I remembered your name correctly)...\\n \\n    You asked about insurance for performance cars.  Well, last year\\n    I was in a similar situation before I bought my car, and made the\\n    same inquiry as you.\\n \\n    Age: 24 (then and now)\\n    Car: 1992 Eagle Talon TSi AWD\\n    Driving Record: Clean\\n    State: Illinois\\n    Cost: $820/6 mos.\\n \\n    I turn 25 in May and the insurance goes down to $520/6 mos.\\n    Also, I\\'m single and that incurs a higher rate with my company.\\n \\n    I\\'ve got a couple other friends w/ AWDs and they pay more\\n    than I do (different ins. companies also), so maybe I\\'m just lucky.\\n \\n    Hope the info helps.\\n \\n    Dan\\n    [dans@jdc.gss.mot.com]\\n    Motorola Cellular Subscriber Group\\n \\n======================================================================== 38\\n USA\\nCc:\\n \\nI\\'m 23; live in Norman, Oklahoma; drive an \\'89 Thunderbird SC; have\\nnever made a claim against my insurance (though I have been hit\\nseveral times by negligent drivers who couldn\\'t see stop signs or\\nwere fiddling with their radios); and I have had three moving violations\\nin the last 18 months (one for going 85 in a 55; one for \"failure to\\nclear an intersection\" (I still say the damn light was yellow); and\\none for going 35 in a 25 (which didn\\'t go on my record)). My rates\\nfrom State Farm (with a passive restraint deduction) on liability,\\n$500 deductible comprehensive, and $500 deductible collision are\\nroughly $1300/year. (I was paying just over $1100/year for a \\'92 Escort LX.)\\n \\n\\t\\t\\t\\tJames\\n \\nJames P. Callison    Microcomputer Coordinator, U of Oklahoma Law Center\\nCallison@uokmax.ecn.uoknor.edu   /\\\\    Callison@aardvark.ucs.uoknor.edu\\nDISCLAIMER: I\\'m not an engineer, but I play one at work...\\n\\t\\tThe forecast calls for Thunder...\\'89 T-Bird SC\\n   \"It\\'s a hell of a thing, killing a man. You take away all he has\\n\\tand all he\\'s ever gonna have.\"\\n\\t\\t\\t--Will Munny, \"Unforgiven\"\\n======================================================================== 61\\n \\nI am beyond the \"under 25\" age group, but I have an experience a few\\nyears ago that might be interesting to you.  I owned a 1985 Toyota Celica\\nGT.  I decided to buy myself a gift - a more exotic car.  Front runners\\nincluded the Toyota Supra Turbo and the Porsche 924 (1987 model years).\\nI narrowed it down to those two.  I liked the simplicity and handling\\n(and snob appeal, too) of driving a Porsche.  The Supra Turbo was less\\nmoney and had more features and performance - almost a personal luxury\\ncar.  It had better acceleration and a higher top speed than the 924.\\nI was almost ready to give in to a buying impulse for the 924, but i\\ndecided to stop by my insurance agent\\'s office on the way.  I asked\\nabout what would happen to my rate with either car.\\n \\n\"If you buy the Supra, your rate classification will be the same as\\nthe Celica (the \\'85 Celica was considered a subcompact and for that\\nyear was rated as one of the safest cars), with a slight increase because\\nthe car will be 2 years newer.  Our lower-risk division will continue\\nto handle your account.\\n \\n\"If you buy the Porsche 924, we\\'ll have to change you to the standard\\n[higher] rate company and your rate will double.  And if you go with\\na 944, it\\'s another story again - we\\'ll cover the rest of this year,\\nbut cancel you after that.\"\\n \\n\"But the Supra is much faster than the 924, and the 924 is actually\\nfaster than the [standard] 944.  That doens\\'t make sense.\"\\n \\n That\\'s what the book says.  We don\\'t insure Corvettes, either.  For\\nsome reason, the underwriters consider Supras - and their drivers -\\nas very traditional and conservative.\"\\n \\nI eventually went with the Supra for a number of reasons.  The Porsche\\ndealer had a nice salesman to get me interested, but a tough high-pressure\\nguy in the back room.  At equal monthly payments, it would have taken\\na year longer to pay for the Porsche, plus its higher insurance.  I\\nconcluded that the high insurance was related to probability of auto\\ntheft.\\n \\n   /|/| /||)|/  /~ /\\\\| |\\\\|)[~|)/~   |   Everyone\\'s entitled to MY opinion.\\n  / | |/ ||\\\\|\\\\  \\\\_|\\\\/|_|/|)[_|\\\\\\\\_|  |      goldberg@oasys.dt.navy.mil\\n========Imagination is more important than knowledge. - Albert Einstein=======\\n \\n \\n \\n \\n \\n======================================================================== 32\\n \\nI live in Idaho.  When I was <26 many years ago (10 years) I bought a Trans\\nAm (new).  Insurance was about $1300/year.  When I turned 26, it immediately\\ndropped to $460/year.  I had not had any accidents before or after, this was\\nstrictly an age change.  That same rate stayed pretty much the same until I\\nsold the car 2 years ago.  My F-150 pickup is about $80/year less.\\n \\nThe real amazing thing is that when I woke up at age 25, I felt SO MUCH MORE\\nRESPONSIBLE than I was before...  :-)\\n \\nWes\\n \\n======================================================================== 21\\n \\n \\nFor your information:\\nCalifornia\\nMale, single, under 25 , No moving violation\\nAlfa Spider\\n     =======> $2000 / year\\n \\nWhat a bargain!!!\\n======================================================================== 28\\n \\nLet\\'s see, I\\'m 24, single, male, clean driving record. I have a 92 VW COrrado\\nVR6. I live in San Jose, California. I pay ~1500$ a year through Allstate. A\\ngood deal if you ask me.\\n \\nI was thinking about getting a Talon, but I think the insurance is higher\\nfor a \"turbo\" sports car vs a V6\\n \\n-W\\n \\n======================================================================== 27\\n \\n1986 Honda CRX Si, clean record, in a small New Mexico town was around $800\\nper year, age 24.\\n \\nNearby city rates were 1.5X-2X higher than where I\\'ve got mine insured.\\n \\n..robert\\n--\\nRobert Stack / Institute of Transportation Studies, Univ of California-Irvine\\n               stack@translab.its.uci.edu   \\'92 Mazda Protege LX\\n======================================================================== 37\\n1300 per year, 1992 Saturn SC, 21 Years old, State: New Mexico,\\nInsurance: State Farm.\\n \\n \\n======================================================================== 64\\n \\n \\nHere is my info:\\n \\nCar             : \\'89 Toyota Celica ST\\nInsurance Co    : Farmer\\'s Insurance\\nYearly insurance: $2028\\nAge             : 24\\nDate of license : Oct 14, 1992\\nResidence       : Mountain View, California\\nNo moving violations (for now atleast ;-)\\n \\nHope this helps. Please post a summary if possible.\\n \\nVijay\\n**********************************************************************\\nVijay Anisetti\\nEmail: anisetti@informix.com   Apt: (415)962-0320   Off: (415)926-6547\\n======================================================================== 38\\nSingle, 24 years old, Eagle Talon Turbo AWD, $1200 (full-cover, reasonable\\n liability)\\nNo tickets, No violations, No accidents... (knock on wood...)\\nMass,\\n \\n\\tOne thing that makes a HUGE difference in MASS is the town you live in.\\nI\\'m personally in one of the best towns within reasonable distance\\nof Boston.  If I moved to the absolute best it would go down to about\\n$1150, if I moved to the worst it would be $2000+..\\n \\n\\tAlso one accident and a couple of tickets, would probably add another $600...\\n \\n \\n\\t_RV\\n \\n \\n======================================================================== 43\\nI have a 1990 Mitsubishi eclipse turbo awd, am 23 years old and have no\\ntickets that went on my record.  I live in Illinois just outside of Chicago\\nand pay $1560 a year with full coverage at State Farm.  I did get a small\\ndiscount because of my alarm system($30 a year).  I only live 15 miles from\\nChicago but if I actually lived in the city the price would be about $2000\\na year.\\n======================================================================== 41\\nI\\'m over 25, but in case you\\'re interested anyway, I\\'m insuring a 93 SHO\\nfor $287/6 month.  Thats 100k personal+300k total+100k property with\\n250 deductible, glass and towing, State Farm.\\n \\n======================================================================== 39\\n \\nUnless you are under 20 or have been driving for less than 5\\nyears, I think you are being seriously ripped off.  I don\\'t have\\none of the performance cars you listed, but if your record is\\nclean, then you should not be paying over $2K.\\n \\nDid you try calling all the insurance dealers you could find?\\nAlthough rates are supposed to be standardized, I\\'ve found that\\nmost places I initially call, give me some ridiculously high\\nquote and *finaly*, I hit one that is much lower.\\n \\nAlso, I have changed insurance companies when the rate went up at\\nrenewal (no accidents, tickets, car gets older??) to maintain a low\\nrate.  You always have to be careful when it comes to insurance\\ncompanies 8^).\\n \\nGood luck,\\nSerge\\n',\n",
       " 'From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: SEEKING THERMOCOUPLE AMPLIFIER CIRCUIT\\nReply-To: ritley@uiucmrl.bitnet ()\\nOrganization: Materials Research Lab\\nLines: 17\\n\\n\\n\\nI would like to be able to amplify a voltage signal which is\\noutput from a thermocouple, preferably by a factor of\\n100 or 1000 ---- so that the resulting voltage can be fed\\nmore easily into a personal-computer-based ADC data\\nacquisition card.\\n\\nMight anyone be able to point me to references to such\\ncircuits?  I have seen simple amplifier circuits before, but\\nI am not sure how well they work in practice.\\n\\nIn this case, I\\'d like something which will amplify sufficiently\\n\"nicely\" to be used for thermocouples (say, a few degrees\\naccuracy or better).\\n\\nAny pointers would be greatly appreciated!\\n',\n",
       " 'From: abarden@tybse1.uucp (Ann Marie Barden)\\nSubject: X-Terminal Config. file question\\nOrganization: Tybrin Corporation, Shalimar, FL\\nDistribution: usa\\nLines: 19\\n\\n  QUESTION:\\n  What is the EXACT entry (parameter and syntax please), in the X-Terminal\\nconfiguration file (loaded when the X-Terminal boots), to add another system \\nto the TCP/IP access control list?   \\n\\n  BACKGROUND:\\n  I have two unix systems, 1. an AT&T 3B2 running X11R3 and MIT\\'s X11R4 and \\n2. a Sun SS10 without any X.  \\n  I want to have a window to the Sun and the 3B2 on the NCD X-Terminal at the\\nsame time.  I can do this if I manually set the Network Parameter TCP/IP\\nAccess Control List to off, then login to my telnet session. Not Great!  \\n  I\\'ve tried to get \"xhost\" to work and failed.  Either my syntax is wrong\\nor the X11R3 implementation is bogus.  \\n  I am trying to edit the NCD configuration file that is loaded when the \\nNCD boots.  No matter what entry I add or edit, the NCD still boots with\\nthe TCP/IP Access Control list containing only the 3B2.\\n  My manuals are worthless so any help would be most appreciated!!  Thanks!\\n\\nAnn Marie Barden  \\tabarden@afseo.eglin.af.mil\\n']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5182 unique tokens.\n",
      "(80, 500)\n",
      "Total 400000 word vectors.\n",
      "Filter   5\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 500, 100)     518300      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 500, 10, 10)  0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 500, 10, 128  5248        ['reshape_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 500, 10, 128  11648       ['reshape_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 500, 10, 128  20608       ['reshape_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 500, 10, 128  32128       ['reshape_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 500, 10, 128  46208       ['reshape_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_38 (AverageP  (None, 100, 10, 128  0          ['conv2d_38[0][0]']              \n",
      " ooling2D)                      )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_39 (AverageP  (None, 100, 10, 128  0          ['conv2d_39[0][0]']              \n",
      " ooling2D)                      )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_40 (AverageP  (None, 100, 10, 128  0          ['conv2d_40[0][0]']              \n",
      " ooling2D)                      )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_41 (AverageP  (None, 100, 10, 128  0          ['conv2d_41[0][0]']              \n",
      " ooling2D)                      )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_42 (AverageP  (None, 100, 10, 128  0          ['conv2d_42[0][0]']              \n",
      " ooling2D)                      )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 500, 10, 128  0           ['average_pooling2d_38[0][0]',   \n",
      "                                )                                 'average_pooling2d_39[0][0]',   \n",
      "                                                                  'average_pooling2d_40[0][0]',   \n",
      "                                                                  'average_pooling2d_41[0][0]',   \n",
      "                                                                  'average_pooling2d_42[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 500, 10, 128  409728      ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_43 (AverageP  (None, 100, 5, 128)  0          ['conv2d_43[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 100, 5, 128)  409728      ['average_pooling2d_43[0][0]']   \n",
      "                                                                                                  \n",
      " average_pooling2d_44 (AverageP  (None, 20, 3, 128)  0           ['conv2d_44[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 20, 3, 128)   0           ['average_pooling2d_44[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 7680)         0           ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 12)           92172       ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 12)           0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 20)           260         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,546,028\n",
      "Trainable params: 1,546,028\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 - 7s - loss: 2.9964 - accuracy: 0.0750 - val_loss: 3.0472 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 2/1000\n",
      "1/1 - 8s - loss: 3.2675 - accuracy: 0.0500 - val_loss: 2.9923 - val_accuracy: 0.0000e+00 - 8s/epoch - 8s/step\n",
      "Epoch 3/1000\n",
      "1/1 - 8s - loss: 2.9525 - accuracy: 0.1000 - val_loss: 2.9801 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 4/1000\n",
      "1/1 - 8s - loss: 2.9882 - accuracy: 0.0500 - val_loss: 2.9919 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 5/1000\n",
      "1/1 - 8s - loss: 2.9785 - accuracy: 0.0750 - val_loss: 3.0005 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 6/1000\n",
      "1/1 - 8s - loss: 2.9867 - accuracy: 0.1000 - val_loss: 2.9936 - val_accuracy: 0.1500 - 8s/epoch - 8s/step\n",
      "Epoch 7/1000\n",
      "1/1 - 8s - loss: 3.0379 - accuracy: 0.0750 - val_loss: 2.9870 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 8/1000\n",
      "1/1 - 8s - loss: 2.9574 - accuracy: 0.0250 - val_loss: 2.9899 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 9/1000\n",
      "1/1 - 8s - loss: 2.9393 - accuracy: 0.1000 - val_loss: 2.9919 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 10/1000\n",
      "1/1 - 8s - loss: 2.9481 - accuracy: 0.0750 - val_loss: 2.9939 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 11/1000\n",
      "1/1 - 7s - loss: 3.0034 - accuracy: 0.0500 - val_loss: 2.9976 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "1/1 - 7s - loss: 2.9589 - accuracy: 0.1000 - val_loss: 3.0019 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 13/1000\n",
      "1/1 - 8s - loss: 2.9802 - accuracy: 0.0500 - val_loss: 3.0061 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 14/1000\n",
      "1/1 - 8s - loss: 2.8998 - accuracy: 0.0500 - val_loss: 3.0131 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 15/1000\n",
      "1/1 - 7s - loss: 2.9718 - accuracy: 0.0000e+00 - val_loss: 3.0198 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 16/1000\n",
      "1/1 - 7s - loss: 2.9465 - accuracy: 0.0000e+00 - val_loss: 3.0199 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 17/1000\n",
      "1/1 - 7s - loss: 3.0090 - accuracy: 0.0250 - val_loss: 3.0094 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 18/1000\n",
      "1/1 - 7s - loss: 3.0234 - accuracy: 0.0250 - val_loss: 2.9983 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 19/1000\n",
      "1/1 - 7s - loss: 2.9576 - accuracy: 0.1000 - val_loss: 2.9916 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 20/1000\n",
      "1/1 - 8s - loss: 2.8935 - accuracy: 0.1250 - val_loss: 2.9897 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 21/1000\n",
      "1/1 - 10s - loss: 2.9216 - accuracy: 0.1500 - val_loss: 2.9936 - val_accuracy: 0.1500 - 10s/epoch - 10s/step\n",
      "Epoch 22/1000\n",
      "1/1 - 8s - loss: 2.9296 - accuracy: 0.0500 - val_loss: 2.9991 - val_accuracy: 0.1500 - 8s/epoch - 8s/step\n",
      "Epoch 23/1000\n",
      "1/1 - 9s - loss: 2.8853 - accuracy: 0.1500 - val_loss: 3.0093 - val_accuracy: 0.1250 - 9s/epoch - 9s/step\n",
      "Epoch 24/1000\n",
      "1/1 - 9s - loss: 2.8854 - accuracy: 0.0500 - val_loss: 3.0292 - val_accuracy: 0.1250 - 9s/epoch - 9s/step\n",
      "Epoch 25/1000\n",
      "1/1 - 9s - loss: 2.9534 - accuracy: 0.0750 - val_loss: 3.0460 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 26/1000\n",
      "1/1 - 8s - loss: 2.9648 - accuracy: 0.0750 - val_loss: 3.0484 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 27/1000\n",
      "1/1 - 8s - loss: 2.9940 - accuracy: 0.1000 - val_loss: 3.0372 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 28/1000\n",
      "1/1 - 8s - loss: 2.9072 - accuracy: 0.0750 - val_loss: 3.0241 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 29/1000\n",
      "1/1 - 9s - loss: 2.8697 - accuracy: 0.0750 - val_loss: 3.0212 - val_accuracy: 0.1250 - 9s/epoch - 9s/step\n",
      "Epoch 30/1000\n",
      "1/1 - 8s - loss: 2.8719 - accuracy: 0.0750 - val_loss: 3.0163 - val_accuracy: 0.1500 - 8s/epoch - 8s/step\n",
      "Epoch 31/1000\n",
      "1/1 - 8s - loss: 2.9203 - accuracy: 0.0500 - val_loss: 3.0080 - val_accuracy: 0.1500 - 8s/epoch - 8s/step\n",
      "Epoch 32/1000\n",
      "1/1 - 7s - loss: 2.9372 - accuracy: 0.0500 - val_loss: 3.0129 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 33/1000\n",
      "1/1 - 7s - loss: 2.9095 - accuracy: 0.0500 - val_loss: 3.0239 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 34/1000\n",
      "1/1 - 7s - loss: 2.8964 - accuracy: 0.1250 - val_loss: 3.0369 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 35/1000\n",
      "1/1 - 7s - loss: 2.8443 - accuracy: 0.1000 - val_loss: 3.0457 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 36/1000\n",
      "1/1 - 7s - loss: 2.9499 - accuracy: 0.0250 - val_loss: 3.0535 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 37/1000\n",
      "1/1 - 8s - loss: 2.8652 - accuracy: 0.1500 - val_loss: 3.0744 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 38/1000\n",
      "1/1 - 8s - loss: 2.7878 - accuracy: 0.1500 - val_loss: 3.1267 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 39/1000\n",
      "1/1 - 7s - loss: 2.8678 - accuracy: 0.1000 - val_loss: 3.1596 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 40/1000\n",
      "1/1 - 8s - loss: 2.8439 - accuracy: 0.0750 - val_loss: 3.1540 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 41/1000\n",
      "1/1 - 8s - loss: 2.8847 - accuracy: 0.0750 - val_loss: 3.1417 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 42/1000\n",
      "1/1 - 8s - loss: 2.8674 - accuracy: 0.0500 - val_loss: 3.0994 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 43/1000\n",
      "1/1 - 7s - loss: 2.7815 - accuracy: 0.1500 - val_loss: 3.0622 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 44/1000\n",
      "1/1 - 8s - loss: 2.8621 - accuracy: 0.1750 - val_loss: 3.0416 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 45/1000\n",
      "1/1 - 8s - loss: 2.8763 - accuracy: 0.0750 - val_loss: 3.0244 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 46/1000\n",
      "1/1 - 9s - loss: 2.8751 - accuracy: 0.1500 - val_loss: 3.0074 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 47/1000\n",
      "1/1 - 8s - loss: 2.7999 - accuracy: 0.1750 - val_loss: 3.0037 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 48/1000\n",
      "1/1 - 8s - loss: 2.9274 - accuracy: 0.0750 - val_loss: 2.9947 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 49/1000\n",
      "1/1 - 8s - loss: 2.7825 - accuracy: 0.1500 - val_loss: 3.0028 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 50/1000\n",
      "1/1 - 8s - loss: 2.8992 - accuracy: 0.1000 - val_loss: 3.0126 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 51/1000\n",
      "1/1 - 8s - loss: 2.8068 - accuracy: 0.1500 - val_loss: 3.0257 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 52/1000\n",
      "1/1 - 8s - loss: 2.7776 - accuracy: 0.2000 - val_loss: 3.0536 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 53/1000\n",
      "1/1 - 8s - loss: 2.8351 - accuracy: 0.1500 - val_loss: 3.0722 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 54/1000\n",
      "1/1 - 8s - loss: 2.8220 - accuracy: 0.1000 - val_loss: 3.0750 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 55/1000\n",
      "1/1 - 8s - loss: 2.8741 - accuracy: 0.1250 - val_loss: 3.0673 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 56/1000\n",
      "1/1 - 7s - loss: 2.6985 - accuracy: 0.2500 - val_loss: 3.0776 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 57/1000\n",
      "1/1 - 7s - loss: 2.7786 - accuracy: 0.1000 - val_loss: 3.0907 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 58/1000\n",
      "1/1 - 7s - loss: 2.8748 - accuracy: 0.1000 - val_loss: 3.1118 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 59/1000\n",
      "1/1 - 7s - loss: 2.8000 - accuracy: 0.1500 - val_loss: 3.1299 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 60/1000\n",
      "1/1 - 7s - loss: 2.8413 - accuracy: 0.0750 - val_loss: 3.0996 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 61/1000\n",
      "1/1 - 7s - loss: 2.7903 - accuracy: 0.1250 - val_loss: 3.0763 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 62/1000\n",
      "1/1 - 7s - loss: 2.7135 - accuracy: 0.1000 - val_loss: 3.0729 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 63/1000\n",
      "1/1 - 7s - loss: 2.7708 - accuracy: 0.1250 - val_loss: 3.0779 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 64/1000\n",
      "1/1 - 8s - loss: 2.7332 - accuracy: 0.1250 - val_loss: 3.0904 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 65/1000\n",
      "1/1 - 7s - loss: 2.6601 - accuracy: 0.0750 - val_loss: 3.1160 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 66/1000\n",
      "1/1 - 7s - loss: 2.7503 - accuracy: 0.1750 - val_loss: 3.1482 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 67/1000\n",
      "1/1 - 7s - loss: 2.8696 - accuracy: 0.1250 - val_loss: 3.1904 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 68/1000\n",
      "1/1 - 7s - loss: 2.6661 - accuracy: 0.1750 - val_loss: 3.2178 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 69/1000\n",
      "1/1 - 7s - loss: 2.7227 - accuracy: 0.1000 - val_loss: 3.2348 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 70/1000\n",
      "1/1 - 7s - loss: 2.6650 - accuracy: 0.1250 - val_loss: 3.2069 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 71/1000\n",
      "1/1 - 7s - loss: 2.5965 - accuracy: 0.1250 - val_loss: 3.2018 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 72/1000\n",
      "1/1 - 8s - loss: 2.6522 - accuracy: 0.1000 - val_loss: 3.2049 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 73/1000\n",
      "1/1 - 7s - loss: 2.7848 - accuracy: 0.1750 - val_loss: 3.2091 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 74/1000\n",
      "1/1 - 8s - loss: 2.6075 - accuracy: 0.1750 - val_loss: 3.2561 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 75/1000\n",
      "1/1 - 7s - loss: 2.6808 - accuracy: 0.1250 - val_loss: 3.3201 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 76/1000\n",
      "1/1 - 7s - loss: 2.7067 - accuracy: 0.1000 - val_loss: 3.2870 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 77/1000\n",
      "1/1 - 7s - loss: 2.6532 - accuracy: 0.0500 - val_loss: 3.2231 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 78/1000\n",
      "1/1 - 8s - loss: 2.5294 - accuracy: 0.1250 - val_loss: 3.2107 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 79/1000\n",
      "1/1 - 7s - loss: 2.5321 - accuracy: 0.1500 - val_loss: 3.2409 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 80/1000\n",
      "1/1 - 7s - loss: 2.6429 - accuracy: 0.1500 - val_loss: 3.2592 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "1/1 - 8s - loss: 2.7625 - accuracy: 0.0750 - val_loss: 3.2058 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 82/1000\n",
      "1/1 - 7s - loss: 2.5712 - accuracy: 0.2250 - val_loss: 3.1814 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 83/1000\n",
      "1/1 - 7s - loss: 2.5769 - accuracy: 0.1500 - val_loss: 3.2042 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 84/1000\n",
      "1/1 - 7s - loss: 2.5745 - accuracy: 0.1500 - val_loss: 3.2489 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 85/1000\n",
      "1/1 - 7s - loss: 2.5272 - accuracy: 0.1750 - val_loss: 3.3012 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 86/1000\n",
      "1/1 - 7s - loss: 2.6123 - accuracy: 0.1750 - val_loss: 3.3158 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 87/1000\n",
      "1/1 - 7s - loss: 2.6047 - accuracy: 0.1000 - val_loss: 3.3086 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 88/1000\n",
      "1/1 - 7s - loss: 2.5185 - accuracy: 0.1750 - val_loss: 3.3029 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 89/1000\n",
      "1/1 - 8s - loss: 2.5673 - accuracy: 0.1500 - val_loss: 3.2983 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 90/1000\n",
      "1/1 - 7s - loss: 2.4036 - accuracy: 0.2000 - val_loss: 3.2773 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 91/1000\n",
      "1/1 - 8s - loss: 2.5661 - accuracy: 0.1500 - val_loss: 3.2615 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 92/1000\n",
      "1/1 - 7s - loss: 2.4688 - accuracy: 0.1750 - val_loss: 3.2672 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 93/1000\n",
      "1/1 - 7s - loss: 2.6209 - accuracy: 0.1000 - val_loss: 3.2892 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 94/1000\n",
      "1/1 - 7s - loss: 2.5272 - accuracy: 0.1250 - val_loss: 3.3115 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 95/1000\n",
      "1/1 - 7s - loss: 2.5054 - accuracy: 0.2000 - val_loss: 3.3379 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 96/1000\n",
      "1/1 - 7s - loss: 2.3821 - accuracy: 0.1750 - val_loss: 3.3494 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 97/1000\n",
      "1/1 - 7s - loss: 2.3660 - accuracy: 0.2500 - val_loss: 3.4024 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 98/1000\n",
      "1/1 - 7s - loss: 2.3454 - accuracy: 0.2000 - val_loss: 3.4908 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 99/1000\n",
      "1/1 - 7s - loss: 2.4332 - accuracy: 0.2750 - val_loss: 3.6176 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 100/1000\n",
      "1/1 - 7s - loss: 2.3894 - accuracy: 0.1000 - val_loss: 3.6587 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 101/1000\n",
      "1/1 - 7s - loss: 2.4355 - accuracy: 0.1500 - val_loss: 3.6757 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 102/1000\n",
      "1/1 - 7s - loss: 2.4551 - accuracy: 0.1500 - val_loss: 3.6659 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 103/1000\n",
      "1/1 - 7s - loss: 2.4755 - accuracy: 0.1750 - val_loss: 3.5834 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 104/1000\n",
      "1/1 - 8s - loss: 2.5098 - accuracy: 0.1250 - val_loss: 3.4968 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 105/1000\n",
      "1/1 - 7s - loss: 2.3207 - accuracy: 0.1500 - val_loss: 3.4255 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 106/1000\n",
      "1/1 - 8s - loss: 2.4365 - accuracy: 0.1000 - val_loss: 3.3672 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 107/1000\n",
      "1/1 - 7s - loss: 2.4613 - accuracy: 0.1000 - val_loss: 3.3283 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 108/1000\n",
      "1/1 - 8s - loss: 2.4283 - accuracy: 0.2250 - val_loss: 3.3160 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 109/1000\n",
      "1/1 - 7s - loss: 2.4950 - accuracy: 0.1500 - val_loss: 3.3347 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 110/1000\n",
      "1/1 - 7s - loss: 2.3685 - accuracy: 0.1250 - val_loss: 3.3412 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 111/1000\n",
      "1/1 - 7s - loss: 2.2410 - accuracy: 0.2750 - val_loss: 3.3876 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 112/1000\n",
      "1/1 - 7s - loss: 2.5419 - accuracy: 0.1750 - val_loss: 3.4494 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 113/1000\n",
      "1/1 - 7s - loss: 2.2410 - accuracy: 0.2000 - val_loss: 3.5151 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 114/1000\n",
      "1/1 - 7s - loss: 2.3394 - accuracy: 0.1500 - val_loss: 3.5501 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 115/1000\n",
      "1/1 - 7s - loss: 2.4418 - accuracy: 0.1250 - val_loss: 3.5940 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 116/1000\n",
      "1/1 - 7s - loss: 2.2416 - accuracy: 0.1500 - val_loss: 3.5930 - val_accuracy: 0.1500 - 7s/epoch - 7s/step\n",
      "Epoch 117/1000\n",
      "1/1 - 8s - loss: 2.2767 - accuracy: 0.1250 - val_loss: 3.6097 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 118/1000\n",
      "1/1 - 7s - loss: 2.1986 - accuracy: 0.1250 - val_loss: 3.6472 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 119/1000\n",
      "1/1 - 8s - loss: 2.0322 - accuracy: 0.1750 - val_loss: 3.7396 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 120/1000\n",
      "1/1 - 7s - loss: 2.2861 - accuracy: 0.2250 - val_loss: 3.8319 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 121/1000\n",
      "1/1 - 7s - loss: 2.1457 - accuracy: 0.2500 - val_loss: 3.8190 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 122/1000\n",
      "1/1 - 7s - loss: 2.2327 - accuracy: 0.2000 - val_loss: 3.7832 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 123/1000\n",
      "1/1 - 7s - loss: 2.6129 - accuracy: 0.0750 - val_loss: 3.6059 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 124/1000\n",
      "1/1 - 7s - loss: 2.2022 - accuracy: 0.2250 - val_loss: 3.5211 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 125/1000\n",
      "1/1 - 7s - loss: 2.4779 - accuracy: 0.0750 - val_loss: 3.5114 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 126/1000\n",
      "1/1 - 7s - loss: 2.3790 - accuracy: 0.1750 - val_loss: 3.5426 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 127/1000\n",
      "1/1 - 7s - loss: 2.2871 - accuracy: 0.1750 - val_loss: 3.6199 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 128/1000\n",
      "1/1 - 8s - loss: 2.0592 - accuracy: 0.2000 - val_loss: 3.7282 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 129/1000\n",
      "1/1 - 7s - loss: 2.3191 - accuracy: 0.1750 - val_loss: 3.8747 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 130/1000\n",
      "1/1 - 7s - loss: 2.1847 - accuracy: 0.2250 - val_loss: 4.0322 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 131/1000\n",
      "1/1 - 7s - loss: 2.3010 - accuracy: 0.1750 - val_loss: 4.1104 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 132/1000\n",
      "1/1 - 7s - loss: 2.3369 - accuracy: 0.1000 - val_loss: 4.1362 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 133/1000\n",
      "1/1 - 7s - loss: 2.3063 - accuracy: 0.1000 - val_loss: 4.0300 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 134/1000\n",
      "1/1 - 7s - loss: 2.2281 - accuracy: 0.1500 - val_loss: 3.9440 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 135/1000\n",
      "1/1 - 7s - loss: 2.1868 - accuracy: 0.2000 - val_loss: 3.8557 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 136/1000\n",
      "1/1 - 7s - loss: 2.2744 - accuracy: 0.1750 - val_loss: 3.8388 - val_accuracy: 0.1250 - 7s/epoch - 7s/step\n",
      "Epoch 137/1000\n",
      "1/1 - 7s - loss: 2.0957 - accuracy: 0.3000 - val_loss: 3.8773 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 138/1000\n",
      "1/1 - 8s - loss: 1.9521 - accuracy: 0.2250 - val_loss: 3.9756 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 139/1000\n",
      "1/1 - 8s - loss: 2.2236 - accuracy: 0.2000 - val_loss: 4.0638 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 140/1000\n",
      "1/1 - 7s - loss: 2.2404 - accuracy: 0.2250 - val_loss: 4.1940 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 141/1000\n",
      "1/1 - 7s - loss: 2.1300 - accuracy: 0.2250 - val_loss: 4.3002 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 142/1000\n",
      "1/1 - 7s - loss: 1.9817 - accuracy: 0.3000 - val_loss: 4.4271 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 143/1000\n",
      "1/1 - 8s - loss: 2.1248 - accuracy: 0.1750 - val_loss: 4.5674 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 144/1000\n",
      "1/1 - 7s - loss: 2.1554 - accuracy: 0.2000 - val_loss: 4.7224 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 145/1000\n",
      "1/1 - 7s - loss: 2.1823 - accuracy: 0.2750 - val_loss: 4.7777 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 146/1000\n",
      "1/1 - 7s - loss: 2.1267 - accuracy: 0.2000 - val_loss: 4.7785 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 147/1000\n",
      "1/1 - 7s - loss: 2.1299 - accuracy: 0.2500 - val_loss: 4.6144 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 148/1000\n",
      "1/1 - 7s - loss: 2.2289 - accuracy: 0.2500 - val_loss: 4.3731 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "1/1 - 7s - loss: 2.2659 - accuracy: 0.1500 - val_loss: 4.0962 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 150/1000\n",
      "1/1 - 7s - loss: 2.1186 - accuracy: 0.2250 - val_loss: 3.9550 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 151/1000\n",
      "1/1 - 7s - loss: 2.2400 - accuracy: 0.1500 - val_loss: 3.9596 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 152/1000\n",
      "1/1 - 8s - loss: 2.1734 - accuracy: 0.2500 - val_loss: 3.9773 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 153/1000\n",
      "1/1 - 7s - loss: 2.1368 - accuracy: 0.2500 - val_loss: 4.0210 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 154/1000\n",
      "1/1 - 8s - loss: 2.0000 - accuracy: 0.2250 - val_loss: 4.1457 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 155/1000\n",
      "1/1 - 7s - loss: 1.9566 - accuracy: 0.3250 - val_loss: 4.2385 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 156/1000\n",
      "1/1 - 7s - loss: 2.0256 - accuracy: 0.2750 - val_loss: 4.3086 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 157/1000\n",
      "1/1 - 7s - loss: 2.0449 - accuracy: 0.2000 - val_loss: 4.3137 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 158/1000\n",
      "1/1 - 7s - loss: 2.0930 - accuracy: 0.2750 - val_loss: 4.3817 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 159/1000\n",
      "1/1 - 7s - loss: 2.1927 - accuracy: 0.2000 - val_loss: 4.3885 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 160/1000\n",
      "1/1 - 7s - loss: 2.0502 - accuracy: 0.1750 - val_loss: 4.4577 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 161/1000\n",
      "1/1 - 7s - loss: 2.1031 - accuracy: 0.2250 - val_loss: 4.5959 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 162/1000\n",
      "1/1 - 7s - loss: 1.9602 - accuracy: 0.2500 - val_loss: 4.7194 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 163/1000\n",
      "1/1 - 8s - loss: 1.9840 - accuracy: 0.1750 - val_loss: 4.8910 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 164/1000\n",
      "1/1 - 8s - loss: 2.0589 - accuracy: 0.2250 - val_loss: 5.0112 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 165/1000\n",
      "1/1 - 7s - loss: 2.1015 - accuracy: 0.2500 - val_loss: 5.0838 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 166/1000\n",
      "1/1 - 8s - loss: 2.1683 - accuracy: 0.2000 - val_loss: 5.0234 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 167/1000\n",
      "1/1 - 8s - loss: 2.1213 - accuracy: 0.2000 - val_loss: 4.9737 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 168/1000\n",
      "1/1 - 8s - loss: 2.0598 - accuracy: 0.2750 - val_loss: 4.9581 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 169/1000\n",
      "1/1 - 8s - loss: 2.0378 - accuracy: 0.2500 - val_loss: 4.8711 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 170/1000\n",
      "1/1 - 8s - loss: 1.8066 - accuracy: 0.2750 - val_loss: 4.9056 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 171/1000\n",
      "1/1 - 8s - loss: 1.9899 - accuracy: 0.3250 - val_loss: 4.9170 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 172/1000\n",
      "1/1 - 8s - loss: 2.0236 - accuracy: 0.2500 - val_loss: 4.9402 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 173/1000\n",
      "1/1 - 8s - loss: 2.0721 - accuracy: 0.3250 - val_loss: 4.7244 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 174/1000\n",
      "1/1 - 9s - loss: 1.8860 - accuracy: 0.2750 - val_loss: 4.6947 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 175/1000\n",
      "1/1 - 8s - loss: 2.1144 - accuracy: 0.2000 - val_loss: 4.7399 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 176/1000\n",
      "1/1 - 8s - loss: 2.0180 - accuracy: 0.2250 - val_loss: 4.9281 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 177/1000\n",
      "1/1 - 8s - loss: 2.0788 - accuracy: 0.2250 - val_loss: 4.9605 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 178/1000\n",
      "1/1 - 10s - loss: 1.9560 - accuracy: 0.3500 - val_loss: 4.9132 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 179/1000\n",
      "1/1 - 8s - loss: 1.8934 - accuracy: 0.3000 - val_loss: 4.8335 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 180/1000\n",
      "1/1 - 8s - loss: 2.0207 - accuracy: 0.3000 - val_loss: 4.8063 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 181/1000\n",
      "1/1 - 8s - loss: 1.9028 - accuracy: 0.2000 - val_loss: 4.7571 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 182/1000\n",
      "1/1 - 8s - loss: 2.0925 - accuracy: 0.2750 - val_loss: 4.6393 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 183/1000\n",
      "1/1 - 8s - loss: 2.0821 - accuracy: 0.2250 - val_loss: 4.6546 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 184/1000\n",
      "1/1 - 7s - loss: 1.9305 - accuracy: 0.2500 - val_loss: 4.7965 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 185/1000\n",
      "1/1 - 8s - loss: 1.9518 - accuracy: 0.2000 - val_loss: 5.0890 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 186/1000\n",
      "1/1 - 8s - loss: 2.1756 - accuracy: 0.2000 - val_loss: 5.0692 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 187/1000\n",
      "1/1 - 8s - loss: 1.8284 - accuracy: 0.4000 - val_loss: 5.0439 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 188/1000\n",
      "1/1 - 9s - loss: 1.7757 - accuracy: 0.3500 - val_loss: 5.0573 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 189/1000\n",
      "1/1 - 7s - loss: 1.8393 - accuracy: 0.3500 - val_loss: 5.1074 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 190/1000\n",
      "1/1 - 8s - loss: 2.0200 - accuracy: 0.2000 - val_loss: 5.1125 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 191/1000\n",
      "1/1 - 8s - loss: 2.1302 - accuracy: 0.2000 - val_loss: 5.1426 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 192/1000\n",
      "1/1 - 8s - loss: 1.8755 - accuracy: 0.3000 - val_loss: 5.2041 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 193/1000\n",
      "1/1 - 8s - loss: 2.0051 - accuracy: 0.2250 - val_loss: 5.1143 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 194/1000\n",
      "1/1 - 8s - loss: 2.3109 - accuracy: 0.1750 - val_loss: 4.8748 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 195/1000\n",
      "1/1 - 8s - loss: 1.8960 - accuracy: 0.2750 - val_loss: 4.7298 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 196/1000\n",
      "1/1 - 8s - loss: 2.1620 - accuracy: 0.2000 - val_loss: 4.6501 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 197/1000\n",
      "1/1 - 7s - loss: 1.9397 - accuracy: 0.3500 - val_loss: 4.5986 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 198/1000\n",
      "1/1 - 7s - loss: 1.8650 - accuracy: 0.3250 - val_loss: 4.6706 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 199/1000\n",
      "1/1 - 8s - loss: 2.1987 - accuracy: 0.1500 - val_loss: 4.7456 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 200/1000\n",
      "1/1 - 9s - loss: 1.8676 - accuracy: 0.3500 - val_loss: 5.0520 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 201/1000\n",
      "1/1 - 8s - loss: 2.2103 - accuracy: 0.1750 - val_loss: 5.2974 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 202/1000\n",
      "1/1 - 7s - loss: 1.9763 - accuracy: 0.2250 - val_loss: 5.4185 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 203/1000\n",
      "1/1 - 8s - loss: 1.9726 - accuracy: 0.2250 - val_loss: 5.4117 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 204/1000\n",
      "1/1 - 7s - loss: 2.1252 - accuracy: 0.2250 - val_loss: 5.2335 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 205/1000\n",
      "1/1 - 8s - loss: 1.7149 - accuracy: 0.3750 - val_loss: 4.9705 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 206/1000\n",
      "1/1 - 8s - loss: 1.9643 - accuracy: 0.2750 - val_loss: 4.9149 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 207/1000\n",
      "1/1 - 8s - loss: 1.8297 - accuracy: 0.3500 - val_loss: 4.8284 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 208/1000\n",
      "1/1 - 8s - loss: 1.9097 - accuracy: 0.3750 - val_loss: 4.7889 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 209/1000\n",
      "1/1 - 8s - loss: 2.0756 - accuracy: 0.2250 - val_loss: 4.7526 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 210/1000\n",
      "1/1 - 8s - loss: 1.9947 - accuracy: 0.2500 - val_loss: 4.6764 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 211/1000\n",
      "1/1 - 8s - loss: 1.9461 - accuracy: 0.3000 - val_loss: 4.6360 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 212/1000\n",
      "1/1 - 8s - loss: 1.8513 - accuracy: 0.2500 - val_loss: 4.6664 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 213/1000\n",
      "1/1 - 8s - loss: 1.9846 - accuracy: 0.3000 - val_loss: 4.7391 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 214/1000\n",
      "1/1 - 8s - loss: 1.8351 - accuracy: 0.3500 - val_loss: 4.9271 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 215/1000\n",
      "1/1 - 9s - loss: 2.0429 - accuracy: 0.1750 - val_loss: 5.0674 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 216/1000\n",
      "1/1 - 8s - loss: 2.0334 - accuracy: 0.1750 - val_loss: 5.1842 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "1/1 - 9s - loss: 1.6861 - accuracy: 0.3750 - val_loss: 5.4046 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 218/1000\n",
      "1/1 - 8s - loss: 1.8564 - accuracy: 0.2250 - val_loss: 5.6296 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 219/1000\n",
      "1/1 - 8s - loss: 1.7704 - accuracy: 0.3250 - val_loss: 5.7777 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 220/1000\n",
      "1/1 - 8s - loss: 1.9550 - accuracy: 0.2000 - val_loss: 5.7432 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 221/1000\n",
      "1/1 - 9s - loss: 1.6856 - accuracy: 0.3000 - val_loss: 5.7026 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 222/1000\n",
      "1/1 - 9s - loss: 1.9897 - accuracy: 0.2000 - val_loss: 5.5707 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 223/1000\n",
      "1/1 - 8s - loss: 1.8757 - accuracy: 0.3000 - val_loss: 5.4133 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 224/1000\n",
      "1/1 - 8s - loss: 1.8075 - accuracy: 0.3000 - val_loss: 5.2287 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 225/1000\n",
      "1/1 - 8s - loss: 1.7181 - accuracy: 0.3250 - val_loss: 5.1372 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 226/1000\n",
      "1/1 - 8s - loss: 1.9955 - accuracy: 0.1750 - val_loss: 5.0295 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 227/1000\n",
      "1/1 - 8s - loss: 1.9163 - accuracy: 0.2000 - val_loss: 5.0409 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 228/1000\n",
      "1/1 - 8s - loss: 2.0465 - accuracy: 0.2750 - val_loss: 5.1095 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 229/1000\n",
      "1/1 - 9s - loss: 2.0191 - accuracy: 0.2000 - val_loss: 5.1222 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 230/1000\n",
      "1/1 - 9s - loss: 1.9045 - accuracy: 0.2500 - val_loss: 5.2281 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 231/1000\n",
      "1/1 - 9s - loss: 1.8079 - accuracy: 0.3000 - val_loss: 5.3659 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 232/1000\n",
      "1/1 - 9s - loss: 1.8444 - accuracy: 0.2000 - val_loss: 5.4551 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 233/1000\n",
      "1/1 - 9s - loss: 1.7419 - accuracy: 0.3000 - val_loss: 5.6465 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 234/1000\n",
      "1/1 - 9s - loss: 1.7210 - accuracy: 0.3500 - val_loss: 5.8933 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 235/1000\n",
      "1/1 - 8s - loss: 1.9307 - accuracy: 0.3000 - val_loss: 6.0226 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 236/1000\n",
      "1/1 - 9s - loss: 2.1064 - accuracy: 0.2250 - val_loss: 6.1561 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 237/1000\n",
      "1/1 - 10s - loss: 1.8878 - accuracy: 0.2750 - val_loss: 6.0266 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 238/1000\n",
      "1/1 - 10s - loss: 1.5660 - accuracy: 0.4750 - val_loss: 5.9221 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 239/1000\n",
      "1/1 - 9s - loss: 1.9069 - accuracy: 0.2500 - val_loss: 5.8404 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 240/1000\n",
      "1/1 - 8s - loss: 1.9356 - accuracy: 0.2750 - val_loss: 5.7772 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 241/1000\n",
      "1/1 - 8s - loss: 1.7966 - accuracy: 0.3000 - val_loss: 5.7796 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 242/1000\n",
      "1/1 - 8s - loss: 1.8970 - accuracy: 0.2250 - val_loss: 5.8502 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 243/1000\n",
      "1/1 - 10s - loss: 1.9554 - accuracy: 0.2500 - val_loss: 5.9221 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 244/1000\n",
      "1/1 - 10s - loss: 1.8845 - accuracy: 0.3500 - val_loss: 5.9260 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 245/1000\n",
      "1/1 - 9s - loss: 2.0357 - accuracy: 0.2000 - val_loss: 5.9405 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 246/1000\n",
      "1/1 - 9s - loss: 2.0640 - accuracy: 0.1750 - val_loss: 5.9662 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 247/1000\n",
      "1/1 - 10s - loss: 1.8315 - accuracy: 0.2500 - val_loss: 6.0089 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 248/1000\n",
      "1/1 - 9s - loss: 1.9658 - accuracy: 0.2000 - val_loss: 6.0852 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 249/1000\n",
      "1/1 - 9s - loss: 1.7896 - accuracy: 0.3500 - val_loss: 6.2241 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 250/1000\n",
      "1/1 - 8s - loss: 1.7831 - accuracy: 0.2750 - val_loss: 6.2897 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 251/1000\n",
      "1/1 - 8s - loss: 1.7733 - accuracy: 0.3000 - val_loss: 6.2681 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 252/1000\n",
      "1/1 - 10s - loss: 2.0730 - accuracy: 0.3000 - val_loss: 6.3783 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 253/1000\n",
      "1/1 - 9s - loss: 2.2213 - accuracy: 0.1750 - val_loss: 6.4913 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 254/1000\n",
      "1/1 - 9s - loss: 1.6552 - accuracy: 0.3250 - val_loss: 6.5453 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 255/1000\n",
      "1/1 - 8s - loss: 1.8497 - accuracy: 0.3250 - val_loss: 6.3767 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 256/1000\n",
      "1/1 - 8s - loss: 1.6835 - accuracy: 0.4250 - val_loss: 6.2705 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 257/1000\n",
      "1/1 - 8s - loss: 2.0953 - accuracy: 0.2000 - val_loss: 6.1248 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 258/1000\n",
      "1/1 - 8s - loss: 1.9138 - accuracy: 0.2500 - val_loss: 6.1548 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 259/1000\n",
      "1/1 - 9s - loss: 1.9140 - accuracy: 0.2500 - val_loss: 6.1486 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 260/1000\n",
      "1/1 - 9s - loss: 1.7975 - accuracy: 0.1750 - val_loss: 6.0705 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 261/1000\n",
      "1/1 - 10s - loss: 2.0429 - accuracy: 0.2500 - val_loss: 6.0247 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 262/1000\n",
      "1/1 - 11s - loss: 1.8773 - accuracy: 0.2750 - val_loss: 6.0622 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 263/1000\n",
      "1/1 - 11s - loss: 1.6776 - accuracy: 0.3250 - val_loss: 6.2076 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 264/1000\n",
      "1/1 - 10s - loss: 1.8731 - accuracy: 0.2250 - val_loss: 6.4087 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 265/1000\n",
      "1/1 - 8s - loss: 1.8840 - accuracy: 0.2000 - val_loss: 6.5980 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 266/1000\n",
      "1/1 - 8s - loss: 1.9497 - accuracy: 0.2000 - val_loss: 6.5857 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 267/1000\n",
      "1/1 - 8s - loss: 1.8974 - accuracy: 0.2500 - val_loss: 6.3935 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 268/1000\n",
      "1/1 - 9s - loss: 1.8637 - accuracy: 0.3500 - val_loss: 6.0992 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 269/1000\n",
      "1/1 - 9s - loss: 2.0654 - accuracy: 0.2500 - val_loss: 5.9126 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 270/1000\n",
      "1/1 - 8s - loss: 1.7952 - accuracy: 0.3000 - val_loss: 5.8649 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 271/1000\n",
      "1/1 - 9s - loss: 2.0936 - accuracy: 0.1500 - val_loss: 5.8562 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 272/1000\n",
      "1/1 - 10s - loss: 1.9549 - accuracy: 0.2500 - val_loss: 5.8638 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 273/1000\n",
      "1/1 - 9s - loss: 1.9321 - accuracy: 0.2250 - val_loss: 5.8687 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 274/1000\n",
      "1/1 - 9s - loss: 1.9665 - accuracy: 0.2250 - val_loss: 5.9555 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 275/1000\n",
      "1/1 - 10s - loss: 1.8374 - accuracy: 0.2500 - val_loss: 6.0857 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 276/1000\n",
      "1/1 - 9s - loss: 1.8620 - accuracy: 0.3000 - val_loss: 6.1775 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 277/1000\n",
      "1/1 - 10s - loss: 1.7097 - accuracy: 0.3250 - val_loss: 6.3019 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 278/1000\n",
      "1/1 - 9s - loss: 1.7566 - accuracy: 0.3000 - val_loss: 6.4417 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 279/1000\n",
      "1/1 - 9s - loss: 1.7713 - accuracy: 0.2750 - val_loss: 6.4624 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 280/1000\n",
      "1/1 - 9s - loss: 1.8238 - accuracy: 0.3000 - val_loss: 6.4979 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 281/1000\n",
      "1/1 - 8s - loss: 1.7704 - accuracy: 0.2500 - val_loss: 6.5397 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 282/1000\n",
      "1/1 - 8s - loss: 1.9988 - accuracy: 0.2250 - val_loss: 6.5742 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 283/1000\n",
      "1/1 - 9s - loss: 1.8373 - accuracy: 0.2750 - val_loss: 6.5805 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 284/1000\n",
      "1/1 - 9s - loss: 1.8267 - accuracy: 0.2250 - val_loss: 6.5772 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000\n",
      "1/1 - 8s - loss: 1.5704 - accuracy: 0.3500 - val_loss: 6.6263 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 286/1000\n",
      "1/1 - 9s - loss: 1.8289 - accuracy: 0.1750 - val_loss: 6.6763 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 287/1000\n",
      "1/1 - 9s - loss: 1.8310 - accuracy: 0.3000 - val_loss: 6.6724 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 288/1000\n",
      "1/1 - 9s - loss: 1.5968 - accuracy: 0.3250 - val_loss: 6.7145 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 289/1000\n",
      "1/1 - 9s - loss: 1.7742 - accuracy: 0.2500 - val_loss: 6.7249 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 290/1000\n",
      "1/1 - 10s - loss: 1.7834 - accuracy: 0.2000 - val_loss: 6.6598 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 291/1000\n",
      "1/1 - 9s - loss: 1.6847 - accuracy: 0.3000 - val_loss: 6.5989 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 292/1000\n",
      "1/1 - 10s - loss: 1.8913 - accuracy: 0.3000 - val_loss: 6.6616 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 293/1000\n",
      "1/1 - 10s - loss: 1.6020 - accuracy: 0.3250 - val_loss: 6.7545 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 294/1000\n",
      "1/1 - 9s - loss: 1.7095 - accuracy: 0.3500 - val_loss: 6.8651 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 295/1000\n",
      "1/1 - 11s - loss: 1.8963 - accuracy: 0.3250 - val_loss: 6.9276 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 296/1000\n",
      "1/1 - 9s - loss: 1.8694 - accuracy: 0.2500 - val_loss: 6.9382 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 297/1000\n",
      "1/1 - 10s - loss: 1.9503 - accuracy: 0.2500 - val_loss: 7.0384 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 298/1000\n",
      "1/1 - 10s - loss: 1.9910 - accuracy: 0.2000 - val_loss: 7.1350 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 299/1000\n",
      "1/1 - 9s - loss: 1.6761 - accuracy: 0.4000 - val_loss: 7.2760 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 300/1000\n",
      "1/1 - 8s - loss: 1.8119 - accuracy: 0.2500 - val_loss: 7.2737 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 301/1000\n",
      "1/1 - 9s - loss: 1.7936 - accuracy: 0.2750 - val_loss: 7.1090 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 302/1000\n",
      "1/1 - 13s - loss: 1.9166 - accuracy: 0.2250 - val_loss: 6.9333 - val_accuracy: 0.0750 - 13s/epoch - 13s/step\n",
      "Epoch 303/1000\n",
      "1/1 - 9s - loss: 1.8609 - accuracy: 0.2250 - val_loss: 6.7188 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 304/1000\n",
      "1/1 - 8s - loss: 1.8243 - accuracy: 0.2500 - val_loss: 6.5168 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 305/1000\n",
      "1/1 - 8s - loss: 1.8165 - accuracy: 0.2750 - val_loss: 6.3320 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 306/1000\n",
      "1/1 - 9s - loss: 2.1057 - accuracy: 0.2000 - val_loss: 6.1681 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 307/1000\n",
      "1/1 - 8s - loss: 1.7642 - accuracy: 0.3000 - val_loss: 6.0982 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 308/1000\n",
      "1/1 - 8s - loss: 1.6931 - accuracy: 0.3000 - val_loss: 6.1333 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 309/1000\n",
      "1/1 - 8s - loss: 1.8275 - accuracy: 0.3000 - val_loss: 6.2126 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 310/1000\n",
      "1/1 - 8s - loss: 1.5307 - accuracy: 0.4250 - val_loss: 6.3655 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 311/1000\n",
      "1/1 - 8s - loss: 1.7712 - accuracy: 0.2750 - val_loss: 6.5145 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 312/1000\n",
      "1/1 - 8s - loss: 1.5270 - accuracy: 0.4000 - val_loss: 6.7531 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 313/1000\n",
      "1/1 - 8s - loss: 1.8677 - accuracy: 0.1750 - val_loss: 6.9716 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 314/1000\n",
      "1/1 - 8s - loss: 1.8070 - accuracy: 0.3000 - val_loss: 7.1456 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 315/1000\n",
      "1/1 - 9s - loss: 1.7545 - accuracy: 0.3000 - val_loss: 7.4637 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 316/1000\n",
      "1/1 - 8s - loss: 1.6281 - accuracy: 0.3250 - val_loss: 7.6887 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 317/1000\n",
      "1/1 - 8s - loss: 1.4899 - accuracy: 0.3750 - val_loss: 7.8745 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 318/1000\n",
      "1/1 - 10s - loss: 1.8409 - accuracy: 0.3500 - val_loss: 8.0488 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 319/1000\n",
      "1/1 - 9s - loss: 1.7216 - accuracy: 0.3500 - val_loss: 8.0566 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 320/1000\n",
      "1/1 - 8s - loss: 1.6359 - accuracy: 0.3500 - val_loss: 7.9485 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 321/1000\n",
      "1/1 - 8s - loss: 1.5017 - accuracy: 0.3500 - val_loss: 7.8695 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 322/1000\n",
      "1/1 - 8s - loss: 1.8489 - accuracy: 0.3000 - val_loss: 7.7531 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 323/1000\n",
      "1/1 - 8s - loss: 1.6914 - accuracy: 0.2750 - val_loss: 7.4149 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 324/1000\n",
      "1/1 - 8s - loss: 1.7779 - accuracy: 0.3000 - val_loss: 7.2428 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 325/1000\n",
      "1/1 - 9s - loss: 1.6412 - accuracy: 0.3250 - val_loss: 7.2593 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 326/1000\n",
      "1/1 - 9s - loss: 1.9533 - accuracy: 0.2000 - val_loss: 7.0960 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 327/1000\n",
      "1/1 - 10s - loss: 2.0790 - accuracy: 0.2750 - val_loss: 6.8432 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 328/1000\n",
      "1/1 - 9s - loss: 1.8077 - accuracy: 0.2500 - val_loss: 6.6056 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 329/1000\n",
      "1/1 - 9s - loss: 1.7174 - accuracy: 0.3000 - val_loss: 6.4700 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 330/1000\n",
      "1/1 - 8s - loss: 1.7915 - accuracy: 0.3000 - val_loss: 6.4669 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 331/1000\n",
      "1/1 - 9s - loss: 1.9808 - accuracy: 0.2500 - val_loss: 6.5546 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 332/1000\n",
      "1/1 - 8s - loss: 1.7639 - accuracy: 0.2750 - val_loss: 6.6122 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 333/1000\n",
      "1/1 - 10s - loss: 1.4783 - accuracy: 0.4000 - val_loss: 6.7328 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 334/1000\n",
      "1/1 - 9s - loss: 1.9207 - accuracy: 0.2750 - val_loss: 7.1148 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 335/1000\n",
      "1/1 - 9s - loss: 1.7063 - accuracy: 0.3500 - val_loss: 7.8489 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 336/1000\n",
      "1/1 - 11s - loss: 1.7252 - accuracy: 0.3750 - val_loss: 8.3386 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 337/1000\n",
      "1/1 - 8s - loss: 1.7529 - accuracy: 0.3000 - val_loss: 8.3192 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 338/1000\n",
      "1/1 - 8s - loss: 1.8510 - accuracy: 0.2500 - val_loss: 7.9795 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 339/1000\n",
      "1/1 - 8s - loss: 1.9414 - accuracy: 0.3000 - val_loss: 7.9313 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 340/1000\n",
      "1/1 - 8s - loss: 1.7189 - accuracy: 0.3500 - val_loss: 8.2019 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 341/1000\n",
      "1/1 - 9s - loss: 1.8539 - accuracy: 0.3250 - val_loss: 8.2034 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 342/1000\n",
      "1/1 - 9s - loss: 1.8136 - accuracy: 0.3250 - val_loss: 7.9603 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 343/1000\n",
      "1/1 - 9s - loss: 1.7080 - accuracy: 0.3250 - val_loss: 7.9868 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 344/1000\n",
      "1/1 - 9s - loss: 1.9064 - accuracy: 0.1750 - val_loss: 8.1404 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 345/1000\n",
      "1/1 - 9s - loss: 2.0483 - accuracy: 0.2250 - val_loss: 8.1181 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 346/1000\n",
      "1/1 - 8s - loss: 2.1744 - accuracy: 0.2000 - val_loss: 7.8088 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 347/1000\n",
      "1/1 - 10s - loss: 1.7409 - accuracy: 0.3250 - val_loss: 7.3260 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 348/1000\n",
      "1/1 - 11s - loss: 1.6920 - accuracy: 0.3500 - val_loss: 6.9495 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 349/1000\n",
      "1/1 - 10s - loss: 1.7187 - accuracy: 0.3750 - val_loss: 6.7116 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 350/1000\n",
      "1/1 - 9s - loss: 1.6986 - accuracy: 0.3500 - val_loss: 6.6976 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 351/1000\n",
      "1/1 - 8s - loss: 1.5649 - accuracy: 0.3750 - val_loss: 6.8416 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 352/1000\n",
      "1/1 - 9s - loss: 1.7754 - accuracy: 0.2500 - val_loss: 6.9370 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/1000\n",
      "1/1 - 9s - loss: 1.6784 - accuracy: 0.3250 - val_loss: 7.0211 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 354/1000\n",
      "1/1 - 8s - loss: 1.8950 - accuracy: 0.3250 - val_loss: 7.1405 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 355/1000\n",
      "1/1 - 8s - loss: 1.5209 - accuracy: 0.4000 - val_loss: 7.2742 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 356/1000\n",
      "1/1 - 9s - loss: 1.7928 - accuracy: 0.2500 - val_loss: 7.1778 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 357/1000\n",
      "1/1 - 8s - loss: 1.9359 - accuracy: 0.2250 - val_loss: 7.0421 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 358/1000\n",
      "1/1 - 8s - loss: 1.4115 - accuracy: 0.3500 - val_loss: 6.9603 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 359/1000\n",
      "1/1 - 9s - loss: 1.7972 - accuracy: 0.3000 - val_loss: 6.9011 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 360/1000\n",
      "1/1 - 9s - loss: 1.6512 - accuracy: 0.2750 - val_loss: 6.8473 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 361/1000\n",
      "1/1 - 8s - loss: 1.4811 - accuracy: 0.3500 - val_loss: 6.8998 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 362/1000\n",
      "1/1 - 8s - loss: 1.9433 - accuracy: 0.2500 - val_loss: 7.0106 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 363/1000\n",
      "1/1 - 8s - loss: 1.2716 - accuracy: 0.5000 - val_loss: 7.2377 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 364/1000\n",
      "1/1 - 8s - loss: 1.5168 - accuracy: 0.4000 - val_loss: 7.5014 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 365/1000\n",
      "1/1 - 8s - loss: 1.5948 - accuracy: 0.3000 - val_loss: 7.8065 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 366/1000\n",
      "1/1 - 8s - loss: 1.5902 - accuracy: 0.3250 - val_loss: 8.0155 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 367/1000\n",
      "1/1 - 8s - loss: 1.9409 - accuracy: 0.2500 - val_loss: 8.2843 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 368/1000\n",
      "1/1 - 8s - loss: 1.8314 - accuracy: 0.2750 - val_loss: 8.4136 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 369/1000\n",
      "1/1 - 8s - loss: 2.0077 - accuracy: 0.1750 - val_loss: 8.0078 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 370/1000\n",
      "1/1 - 8s - loss: 1.7937 - accuracy: 0.2000 - val_loss: 7.5528 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 371/1000\n",
      "1/1 - 8s - loss: 1.6964 - accuracy: 0.3500 - val_loss: 7.3792 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 372/1000\n",
      "1/1 - 8s - loss: 1.6173 - accuracy: 0.3750 - val_loss: 7.3589 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 373/1000\n",
      "1/1 - 8s - loss: 1.7652 - accuracy: 0.3000 - val_loss: 7.4138 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 374/1000\n",
      "1/1 - 8s - loss: 1.5919 - accuracy: 0.4250 - val_loss: 7.4712 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 375/1000\n",
      "1/1 - 8s - loss: 1.7284 - accuracy: 0.4000 - val_loss: 7.4898 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 376/1000\n",
      "1/1 - 9s - loss: 2.0570 - accuracy: 0.2500 - val_loss: 7.5347 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 377/1000\n",
      "1/1 - 9s - loss: 1.7433 - accuracy: 0.2500 - val_loss: 7.5590 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 378/1000\n",
      "1/1 - 8s - loss: 1.8843 - accuracy: 0.3000 - val_loss: 7.6057 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 379/1000\n",
      "1/1 - 10s - loss: 1.7412 - accuracy: 0.3250 - val_loss: 7.6046 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 380/1000\n",
      "1/1 - 10s - loss: 1.7767 - accuracy: 0.2500 - val_loss: 7.5249 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 381/1000\n",
      "1/1 - 8s - loss: 1.4514 - accuracy: 0.3750 - val_loss: 7.3687 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 382/1000\n",
      "1/1 - 8s - loss: 1.5993 - accuracy: 0.3500 - val_loss: 7.1912 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 383/1000\n",
      "1/1 - 8s - loss: 1.5670 - accuracy: 0.4000 - val_loss: 7.1143 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 384/1000\n",
      "1/1 - 8s - loss: 1.9072 - accuracy: 0.2500 - val_loss: 7.0937 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 385/1000\n",
      "1/1 - 10s - loss: 1.8538 - accuracy: 0.2500 - val_loss: 7.1088 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 386/1000\n",
      "1/1 - 9s - loss: 2.0706 - accuracy: 0.2000 - val_loss: 7.1175 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 387/1000\n",
      "1/1 - 9s - loss: 1.6069 - accuracy: 0.3000 - val_loss: 7.2156 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 388/1000\n",
      "1/1 - 8s - loss: 1.6050 - accuracy: 0.3250 - val_loss: 7.3683 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 389/1000\n",
      "1/1 - 8s - loss: 1.7740 - accuracy: 0.3000 - val_loss: 7.5738 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 390/1000\n",
      "1/1 - 8s - loss: 1.6409 - accuracy: 0.3250 - val_loss: 7.7933 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 391/1000\n",
      "1/1 - 8s - loss: 1.6419 - accuracy: 0.3000 - val_loss: 7.8663 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 392/1000\n",
      "1/1 - 9s - loss: 1.7871 - accuracy: 0.3000 - val_loss: 7.8568 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 393/1000\n",
      "1/1 - 9s - loss: 1.5255 - accuracy: 0.3500 - val_loss: 7.8589 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 394/1000\n",
      "1/1 - 9s - loss: 1.4733 - accuracy: 0.3500 - val_loss: 7.8704 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 395/1000\n",
      "1/1 - 9s - loss: 1.8346 - accuracy: 0.2250 - val_loss: 8.0478 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 396/1000\n",
      "1/1 - 9s - loss: 1.5529 - accuracy: 0.3000 - val_loss: 8.1646 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 397/1000\n",
      "1/1 - 8s - loss: 1.5142 - accuracy: 0.4000 - val_loss: 8.2724 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 398/1000\n",
      "1/1 - 8s - loss: 1.6409 - accuracy: 0.3750 - val_loss: 8.3008 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 399/1000\n",
      "1/1 - 8s - loss: 1.4757 - accuracy: 0.4000 - val_loss: 8.3093 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 400/1000\n",
      "1/1 - 9s - loss: 1.6241 - accuracy: 0.3750 - val_loss: 8.2794 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 401/1000\n",
      "1/1 - 10s - loss: 1.6604 - accuracy: 0.3500 - val_loss: 8.2431 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 402/1000\n",
      "1/1 - 10s - loss: 1.9117 - accuracy: 0.2750 - val_loss: 8.2294 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 403/1000\n",
      "1/1 - 10s - loss: 1.9617 - accuracy: 0.3250 - val_loss: 8.6793 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 404/1000\n",
      "1/1 - 10s - loss: 1.5417 - accuracy: 0.3750 - val_loss: 8.9603 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 405/1000\n",
      "1/1 - 9s - loss: 1.7946 - accuracy: 0.2750 - val_loss: 9.1981 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 406/1000\n",
      "1/1 - 9s - loss: 1.7034 - accuracy: 0.3500 - val_loss: 8.9082 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 407/1000\n",
      "1/1 - 9s - loss: 1.7879 - accuracy: 0.2250 - val_loss: 8.4275 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 408/1000\n",
      "1/1 - 9s - loss: 1.9002 - accuracy: 0.2500 - val_loss: 7.9479 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 409/1000\n",
      "1/1 - 10s - loss: 1.1309 - accuracy: 0.6000 - val_loss: 7.7734 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 410/1000\n",
      "1/1 - 10s - loss: 1.6913 - accuracy: 0.3500 - val_loss: 7.8910 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 411/1000\n",
      "1/1 - 9s - loss: 1.6601 - accuracy: 0.3500 - val_loss: 8.0127 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 412/1000\n",
      "1/1 - 10s - loss: 1.6379 - accuracy: 0.4000 - val_loss: 8.2707 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 413/1000\n",
      "1/1 - 10s - loss: 1.6932 - accuracy: 0.3500 - val_loss: 8.5922 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 414/1000\n",
      "1/1 - 10s - loss: 1.6082 - accuracy: 0.3250 - val_loss: 8.9182 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 415/1000\n",
      "1/1 - 9s - loss: 1.6167 - accuracy: 0.2500 - val_loss: 9.2414 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 416/1000\n",
      "1/1 - 10s - loss: 1.8728 - accuracy: 0.2750 - val_loss: 9.2925 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 417/1000\n",
      "1/1 - 9s - loss: 1.7827 - accuracy: 0.2750 - val_loss: 9.2092 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 418/1000\n",
      "1/1 - 9s - loss: 1.4926 - accuracy: 0.2750 - val_loss: 8.9491 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 419/1000\n",
      "1/1 - 8s - loss: 1.8063 - accuracy: 0.3250 - val_loss: 8.5059 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 420/1000\n",
      "1/1 - 8s - loss: 1.6630 - accuracy: 0.3500 - val_loss: 8.1481 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "1/1 - 8s - loss: 1.9428 - accuracy: 0.2750 - val_loss: 7.8187 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 422/1000\n",
      "1/1 - 8s - loss: 1.5267 - accuracy: 0.4500 - val_loss: 7.6011 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 423/1000\n",
      "1/1 - 8s - loss: 1.7499 - accuracy: 0.3250 - val_loss: 7.1149 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 424/1000\n",
      "1/1 - 9s - loss: 1.7397 - accuracy: 0.5250 - val_loss: 6.8766 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 425/1000\n",
      "1/1 - 8s - loss: 1.7483 - accuracy: 0.3000 - val_loss: 6.6760 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 426/1000\n",
      "1/1 - 8s - loss: 1.8330 - accuracy: 0.2500 - val_loss: 6.7791 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 427/1000\n",
      "1/1 - 11s - loss: 1.4894 - accuracy: 0.4500 - val_loss: 7.0404 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 428/1000\n",
      "1/1 - 8s - loss: 1.8193 - accuracy: 0.2500 - val_loss: 7.3076 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 429/1000\n",
      "1/1 - 9s - loss: 1.7301 - accuracy: 0.2750 - val_loss: 7.5334 - val_accuracy: 0.1250 - 9s/epoch - 9s/step\n",
      "Epoch 430/1000\n",
      "1/1 - 10s - loss: 1.8356 - accuracy: 0.2750 - val_loss: 7.5749 - val_accuracy: 0.1250 - 10s/epoch - 10s/step\n",
      "Epoch 431/1000\n",
      "1/1 - 11s - loss: 1.9980 - accuracy: 0.2750 - val_loss: 7.4692 - val_accuracy: 0.1250 - 11s/epoch - 11s/step\n",
      "Epoch 432/1000\n",
      "1/1 - 10s - loss: 1.7276 - accuracy: 0.3500 - val_loss: 7.5306 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 433/1000\n",
      "1/1 - 9s - loss: 1.8068 - accuracy: 0.3250 - val_loss: 7.7713 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 434/1000\n",
      "1/1 - 9s - loss: 1.8095 - accuracy: 0.3250 - val_loss: 8.1699 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 435/1000\n",
      "1/1 - 8s - loss: 1.6602 - accuracy: 0.3750 - val_loss: 8.5499 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 436/1000\n",
      "1/1 - 8s - loss: 1.6057 - accuracy: 0.3250 - val_loss: 8.3621 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 437/1000\n",
      "1/1 - 8s - loss: 1.8476 - accuracy: 0.3000 - val_loss: 8.1673 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 438/1000\n",
      "1/1 - 9s - loss: 1.9266 - accuracy: 0.2750 - val_loss: 8.1299 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 439/1000\n",
      "1/1 - 8s - loss: 1.4232 - accuracy: 0.4250 - val_loss: 8.2499 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 440/1000\n",
      "1/1 - 9s - loss: 1.6489 - accuracy: 0.4250 - val_loss: 8.3213 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 441/1000\n",
      "1/1 - 9s - loss: 1.5286 - accuracy: 0.4000 - val_loss: 8.2520 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 442/1000\n",
      "1/1 - 8s - loss: 1.9174 - accuracy: 0.2250 - val_loss: 7.9811 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 443/1000\n",
      "1/1 - 8s - loss: 2.0149 - accuracy: 0.2750 - val_loss: 7.7171 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 444/1000\n",
      "1/1 - 10s - loss: 1.9146 - accuracy: 0.2250 - val_loss: 7.4937 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 445/1000\n",
      "1/1 - 9s - loss: 1.4675 - accuracy: 0.4000 - val_loss: 7.3324 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 446/1000\n",
      "1/1 - 8s - loss: 1.6920 - accuracy: 0.4250 - val_loss: 7.3134 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 447/1000\n",
      "1/1 - 9s - loss: 1.5487 - accuracy: 0.3750 - val_loss: 7.4720 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 448/1000\n",
      "1/1 - 9s - loss: 1.7268 - accuracy: 0.3750 - val_loss: 7.7234 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 449/1000\n",
      "1/1 - 10s - loss: 1.6585 - accuracy: 0.3250 - val_loss: 8.0496 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 450/1000\n",
      "1/1 - 10s - loss: 1.8474 - accuracy: 0.2000 - val_loss: 8.3552 - val_accuracy: 0.1250 - 10s/epoch - 10s/step\n",
      "Epoch 451/1000\n",
      "1/1 - 10s - loss: 1.9360 - accuracy: 0.1750 - val_loss: 8.2338 - val_accuracy: 0.1250 - 10s/epoch - 10s/step\n",
      "Epoch 452/1000\n",
      "1/1 - 9s - loss: 1.4694 - accuracy: 0.3500 - val_loss: 8.0195 - val_accuracy: 0.1250 - 9s/epoch - 9s/step\n",
      "Epoch 453/1000\n",
      "1/1 - 9s - loss: 1.7641 - accuracy: 0.2500 - val_loss: 7.8511 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 454/1000\n",
      "1/1 - 12s - loss: 1.6299 - accuracy: 0.3750 - val_loss: 7.8009 - val_accuracy: 0.1000 - 12s/epoch - 12s/step\n",
      "Epoch 455/1000\n",
      "1/1 - 9s - loss: 2.0462 - accuracy: 0.2000 - val_loss: 7.7031 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 456/1000\n",
      "1/1 - 10s - loss: 1.4939 - accuracy: 0.4250 - val_loss: 7.6778 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 457/1000\n",
      "1/1 - 13s - loss: 1.4946 - accuracy: 0.4000 - val_loss: 7.7160 - val_accuracy: 0.1000 - 13s/epoch - 13s/step\n",
      "Epoch 458/1000\n",
      "1/1 - 10s - loss: 1.6747 - accuracy: 0.3750 - val_loss: 7.7556 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 459/1000\n",
      "1/1 - 10s - loss: 1.4739 - accuracy: 0.4500 - val_loss: 7.8605 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 460/1000\n",
      "1/1 - 10s - loss: 1.6171 - accuracy: 0.4000 - val_loss: 7.9934 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 461/1000\n",
      "1/1 - 10s - loss: 1.4508 - accuracy: 0.3750 - val_loss: 8.1355 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 462/1000\n",
      "1/1 - 11s - loss: 1.9368 - accuracy: 0.2500 - val_loss: 8.2312 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 463/1000\n",
      "1/1 - 12s - loss: 1.4529 - accuracy: 0.4250 - val_loss: 8.3375 - val_accuracy: 0.0500 - 12s/epoch - 12s/step\n",
      "Epoch 464/1000\n",
      "1/1 - 11s - loss: 1.3423 - accuracy: 0.4500 - val_loss: 8.4568 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 465/1000\n",
      "1/1 - 10s - loss: 1.4921 - accuracy: 0.4250 - val_loss: 8.5421 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 466/1000\n",
      "1/1 - 10s - loss: 1.4748 - accuracy: 0.4250 - val_loss: 8.6542 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 467/1000\n",
      "1/1 - 10s - loss: 1.9105 - accuracy: 0.1500 - val_loss: 8.6814 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 468/1000\n",
      "1/1 - 9s - loss: 1.4768 - accuracy: 0.4750 - val_loss: 8.6343 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 469/1000\n",
      "1/1 - 9s - loss: 1.9168 - accuracy: 0.2500 - val_loss: 8.5399 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 470/1000\n",
      "1/1 - 9s - loss: 1.8097 - accuracy: 0.3000 - val_loss: 8.4377 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 471/1000\n",
      "1/1 - 8s - loss: 1.7409 - accuracy: 0.2750 - val_loss: 8.2779 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 472/1000\n",
      "1/1 - 10s - loss: 1.8651 - accuracy: 0.3000 - val_loss: 8.1521 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 473/1000\n",
      "1/1 - 9s - loss: 1.8684 - accuracy: 0.2500 - val_loss: 8.0172 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 474/1000\n",
      "1/1 - 9s - loss: 1.5784 - accuracy: 0.3750 - val_loss: 7.9124 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 475/1000\n",
      "1/1 - 11s - loss: 1.5476 - accuracy: 0.4750 - val_loss: 7.8571 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 476/1000\n",
      "1/1 - 9s - loss: 1.5412 - accuracy: 0.4250 - val_loss: 7.8253 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 477/1000\n",
      "1/1 - 11s - loss: 1.7119 - accuracy: 0.3750 - val_loss: 7.8249 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 478/1000\n",
      "1/1 - 11s - loss: 1.7883 - accuracy: 0.3750 - val_loss: 7.9948 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 479/1000\n",
      "1/1 - 9s - loss: 1.6272 - accuracy: 0.2750 - val_loss: 8.2122 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 480/1000\n",
      "1/1 - 8s - loss: 1.8068 - accuracy: 0.2750 - val_loss: 8.4206 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 481/1000\n",
      "1/1 - 9s - loss: 1.6668 - accuracy: 0.4250 - val_loss: 8.5496 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 482/1000\n",
      "1/1 - 9s - loss: 1.6929 - accuracy: 0.3500 - val_loss: 8.6162 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 483/1000\n",
      "1/1 - 10s - loss: 1.8418 - accuracy: 0.2750 - val_loss: 8.6499 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 484/1000\n",
      "1/1 - 12s - loss: 1.4935 - accuracy: 0.4000 - val_loss: 8.6002 - val_accuracy: 0.1000 - 12s/epoch - 12s/step\n",
      "Epoch 485/1000\n",
      "1/1 - 10s - loss: 1.6311 - accuracy: 0.4250 - val_loss: 8.3285 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 486/1000\n",
      "1/1 - 11s - loss: 1.4278 - accuracy: 0.4250 - val_loss: 8.2322 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 487/1000\n",
      "1/1 - 10s - loss: 1.6984 - accuracy: 0.3000 - val_loss: 8.1735 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/1000\n",
      "1/1 - 9s - loss: 1.4784 - accuracy: 0.4000 - val_loss: 8.2277 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 489/1000\n",
      "1/1 - 8s - loss: 1.4509 - accuracy: 0.5750 - val_loss: 8.3844 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 490/1000\n",
      "1/1 - 8s - loss: 1.7258 - accuracy: 0.3500 - val_loss: 8.6248 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 491/1000\n",
      "1/1 - 8s - loss: 1.5126 - accuracy: 0.4500 - val_loss: 8.8698 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 492/1000\n",
      "1/1 - 8s - loss: 1.6667 - accuracy: 0.3500 - val_loss: 9.0920 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 493/1000\n",
      "1/1 - 8s - loss: 1.8189 - accuracy: 0.3000 - val_loss: 9.3634 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 494/1000\n",
      "1/1 - 8s - loss: 1.5943 - accuracy: 0.4000 - val_loss: 9.5619 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 495/1000\n",
      "1/1 - 8s - loss: 1.6739 - accuracy: 0.3250 - val_loss: 9.7129 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 496/1000\n",
      "1/1 - 8s - loss: 1.5320 - accuracy: 0.3500 - val_loss: 9.7828 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 497/1000\n",
      "1/1 - 8s - loss: 1.5868 - accuracy: 0.4000 - val_loss: 9.9761 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 498/1000\n",
      "1/1 - 8s - loss: 2.0021 - accuracy: 0.1750 - val_loss: 10.0552 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 499/1000\n",
      "1/1 - 8s - loss: 1.6241 - accuracy: 0.3500 - val_loss: 9.9168 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 500/1000\n",
      "1/1 - 8s - loss: 1.4682 - accuracy: 0.4000 - val_loss: 9.4619 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 501/1000\n",
      "1/1 - 8s - loss: 1.5301 - accuracy: 0.3250 - val_loss: 9.0362 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 502/1000\n",
      "1/1 - 8s - loss: 1.8377 - accuracy: 0.3000 - val_loss: 8.8342 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 503/1000\n",
      "1/1 - 8s - loss: 1.5926 - accuracy: 0.3250 - val_loss: 9.3604 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 504/1000\n",
      "1/1 - 8s - loss: 1.8112 - accuracy: 0.3250 - val_loss: 10.1085 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 505/1000\n",
      "1/1 - 8s - loss: 1.7111 - accuracy: 0.2250 - val_loss: 10.6549 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 506/1000\n",
      "1/1 - 8s - loss: 1.7672 - accuracy: 0.3000 - val_loss: 10.9065 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 507/1000\n",
      "1/1 - 8s - loss: 1.9842 - accuracy: 0.2250 - val_loss: 10.6066 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 508/1000\n",
      "1/1 - 8s - loss: 1.7454 - accuracy: 0.2750 - val_loss: 10.0632 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 509/1000\n",
      "1/1 - 8s - loss: 1.6988 - accuracy: 0.3000 - val_loss: 9.6181 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 510/1000\n",
      "1/1 - 8s - loss: 1.6518 - accuracy: 0.3000 - val_loss: 9.2568 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 511/1000\n",
      "1/1 - 9s - loss: 1.6109 - accuracy: 0.4000 - val_loss: 9.0671 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 512/1000\n",
      "1/1 - 8s - loss: 1.7424 - accuracy: 0.2750 - val_loss: 9.1136 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 513/1000\n",
      "1/1 - 8s - loss: 1.7073 - accuracy: 0.3500 - val_loss: 9.2428 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 514/1000\n",
      "1/1 - 8s - loss: 1.7160 - accuracy: 0.4250 - val_loss: 9.4665 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 515/1000\n",
      "1/1 - 8s - loss: 1.8175 - accuracy: 0.2750 - val_loss: 9.6919 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 516/1000\n",
      "1/1 - 8s - loss: 1.5843 - accuracy: 0.3250 - val_loss: 9.7903 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 517/1000\n",
      "1/1 - 8s - loss: 1.5497 - accuracy: 0.3500 - val_loss: 9.8310 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 518/1000\n",
      "1/1 - 8s - loss: 1.5346 - accuracy: 0.3750 - val_loss: 9.8609 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 519/1000\n",
      "1/1 - 8s - loss: 1.9215 - accuracy: 0.3000 - val_loss: 9.9008 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 520/1000\n",
      "1/1 - 8s - loss: 1.8966 - accuracy: 0.2250 - val_loss: 9.9105 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 521/1000\n",
      "1/1 - 8s - loss: 1.5675 - accuracy: 0.4250 - val_loss: 9.8652 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 522/1000\n",
      "1/1 - 8s - loss: 1.7228 - accuracy: 0.3250 - val_loss: 9.7825 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 523/1000\n",
      "1/1 - 10s - loss: 1.6333 - accuracy: 0.3750 - val_loss: 9.6903 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 524/1000\n",
      "1/1 - 9s - loss: 1.8370 - accuracy: 0.2000 - val_loss: 9.5911 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 525/1000\n",
      "1/1 - 10s - loss: 1.4708 - accuracy: 0.4250 - val_loss: 9.4645 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 526/1000\n",
      "1/1 - 10s - loss: 1.3971 - accuracy: 0.4750 - val_loss: 9.3348 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 527/1000\n",
      "1/1 - 9s - loss: 1.8625 - accuracy: 0.2750 - val_loss: 9.2247 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 528/1000\n",
      "1/1 - 9s - loss: 1.5205 - accuracy: 0.4500 - val_loss: 9.0929 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 529/1000\n",
      "1/1 - 8s - loss: 1.3184 - accuracy: 0.4750 - val_loss: 8.9985 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 530/1000\n",
      "1/1 - 8s - loss: 1.6560 - accuracy: 0.3500 - val_loss: 8.9551 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 531/1000\n",
      "1/1 - 8s - loss: 1.6321 - accuracy: 0.4250 - val_loss: 9.2810 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 532/1000\n",
      "1/1 - 8s - loss: 1.8525 - accuracy: 0.3750 - val_loss: 9.8558 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 533/1000\n",
      "1/1 - 7s - loss: 1.6870 - accuracy: 0.3750 - val_loss: 10.4185 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 534/1000\n",
      "1/1 - 8s - loss: 1.4837 - accuracy: 0.3750 - val_loss: 10.8085 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 535/1000\n",
      "1/1 - 9s - loss: 1.6359 - accuracy: 0.4500 - val_loss: 11.2999 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 536/1000\n",
      "1/1 - 9s - loss: 1.7898 - accuracy: 0.3250 - val_loss: 11.4198 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 537/1000\n",
      "1/1 - 8s - loss: 1.7794 - accuracy: 0.2750 - val_loss: 11.4727 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 538/1000\n",
      "1/1 - 8s - loss: 1.7125 - accuracy: 0.2750 - val_loss: 11.4817 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 539/1000\n",
      "1/1 - 8s - loss: 1.5819 - accuracy: 0.4000 - val_loss: 11.4931 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 540/1000\n",
      "1/1 - 9s - loss: 1.6996 - accuracy: 0.3250 - val_loss: 11.3633 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 541/1000\n",
      "1/1 - 10s - loss: 1.6001 - accuracy: 0.2750 - val_loss: 11.1860 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 542/1000\n",
      "1/1 - 11s - loss: 1.5566 - accuracy: 0.3500 - val_loss: 11.0750 - val_accuracy: 0.0250 - 11s/epoch - 11s/step\n",
      "Epoch 543/1000\n",
      "1/1 - 10s - loss: 1.7105 - accuracy: 0.4250 - val_loss: 10.8754 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 544/1000\n",
      "1/1 - 12s - loss: 1.7962 - accuracy: 0.3000 - val_loss: 10.6277 - val_accuracy: 0.0250 - 12s/epoch - 12s/step\n",
      "Epoch 545/1000\n",
      "1/1 - 9s - loss: 1.8546 - accuracy: 0.3750 - val_loss: 10.4968 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 546/1000\n",
      "1/1 - 9s - loss: 1.6247 - accuracy: 0.3750 - val_loss: 10.4235 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 547/1000\n",
      "1/1 - 10s - loss: 1.4786 - accuracy: 0.4500 - val_loss: 10.3449 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 548/1000\n",
      "1/1 - 9s - loss: 1.7543 - accuracy: 0.3250 - val_loss: 10.2246 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 549/1000\n",
      "1/1 - 10s - loss: 1.7469 - accuracy: 0.3750 - val_loss: 10.1520 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 550/1000\n",
      "1/1 - 10s - loss: 1.6673 - accuracy: 0.4000 - val_loss: 10.1010 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 551/1000\n",
      "1/1 - 9s - loss: 1.6712 - accuracy: 0.3500 - val_loss: 10.1975 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 552/1000\n",
      "1/1 - 10s - loss: 1.5983 - accuracy: 0.4000 - val_loss: 10.2394 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 553/1000\n",
      "1/1 - 8s - loss: 1.5514 - accuracy: 0.3750 - val_loss: 10.0390 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 554/1000\n",
      "1/1 - 10s - loss: 1.7366 - accuracy: 0.3250 - val_loss: 9.6724 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 555/1000\n",
      "1/1 - 10s - loss: 1.3315 - accuracy: 0.4250 - val_loss: 9.2963 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "1/1 - 9s - loss: 1.7623 - accuracy: 0.2500 - val_loss: 8.9565 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 557/1000\n",
      "1/1 - 8s - loss: 1.4804 - accuracy: 0.3750 - val_loss: 8.7109 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 558/1000\n",
      "1/1 - 8s - loss: 1.6865 - accuracy: 0.2750 - val_loss: 8.6164 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 559/1000\n",
      "1/1 - 8s - loss: 1.5948 - accuracy: 0.4250 - val_loss: 8.6460 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 560/1000\n",
      "1/1 - 8s - loss: 1.5327 - accuracy: 0.4750 - val_loss: 8.7552 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 561/1000\n",
      "1/1 - 8s - loss: 1.5163 - accuracy: 0.4500 - val_loss: 8.9161 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 562/1000\n",
      "1/1 - 8s - loss: 2.0250 - accuracy: 0.2750 - val_loss: 9.1086 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 563/1000\n",
      "1/1 - 8s - loss: 1.7182 - accuracy: 0.3250 - val_loss: 9.3123 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 564/1000\n",
      "1/1 - 9s - loss: 1.4409 - accuracy: 0.4500 - val_loss: 9.6234 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 565/1000\n",
      "1/1 - 8s - loss: 1.6409 - accuracy: 0.4000 - val_loss: 9.9254 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 566/1000\n",
      "1/1 - 8s - loss: 1.7020 - accuracy: 0.3250 - val_loss: 10.2177 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 567/1000\n",
      "1/1 - 8s - loss: 1.6665 - accuracy: 0.3500 - val_loss: 10.4141 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 568/1000\n",
      "1/1 - 8s - loss: 1.2351 - accuracy: 0.5250 - val_loss: 10.5971 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 569/1000\n",
      "1/1 - 8s - loss: 1.6850 - accuracy: 0.3500 - val_loss: 10.6886 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 570/1000\n",
      "1/1 - 8s - loss: 1.7480 - accuracy: 0.3000 - val_loss: 10.7312 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 571/1000\n",
      "1/1 - 8s - loss: 1.5870 - accuracy: 0.4000 - val_loss: 10.7265 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 572/1000\n",
      "1/1 - 8s - loss: 1.4390 - accuracy: 0.4000 - val_loss: 10.6777 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 573/1000\n",
      "1/1 - 8s - loss: 1.7133 - accuracy: 0.2250 - val_loss: 10.5118 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 574/1000\n",
      "1/1 - 8s - loss: 1.3379 - accuracy: 0.4250 - val_loss: 10.3523 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 575/1000\n",
      "1/1 - 9s - loss: 1.6887 - accuracy: 0.3250 - val_loss: 10.1559 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 576/1000\n",
      "1/1 - 9s - loss: 1.7355 - accuracy: 0.2500 - val_loss: 9.8985 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 577/1000\n",
      "1/1 - 8s - loss: 1.5165 - accuracy: 0.3750 - val_loss: 9.6947 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 578/1000\n",
      "1/1 - 9s - loss: 1.7396 - accuracy: 0.2750 - val_loss: 9.4975 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 579/1000\n",
      "1/1 - 9s - loss: 1.4471 - accuracy: 0.4250 - val_loss: 9.5953 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 580/1000\n",
      "1/1 - 9s - loss: 1.5179 - accuracy: 0.4000 - val_loss: 9.7556 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 581/1000\n",
      "1/1 - 9s - loss: 1.7757 - accuracy: 0.3250 - val_loss: 9.9310 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 582/1000\n",
      "1/1 - 8s - loss: 1.5435 - accuracy: 0.3750 - val_loss: 10.1053 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 583/1000\n",
      "1/1 - 8s - loss: 1.5424 - accuracy: 0.4500 - val_loss: 10.3139 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 584/1000\n",
      "1/1 - 7s - loss: 1.6098 - accuracy: 0.3750 - val_loss: 10.4545 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 585/1000\n",
      "1/1 - 8s - loss: 1.4002 - accuracy: 0.4750 - val_loss: 10.7653 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 586/1000\n",
      "1/1 - 11s - loss: 1.4592 - accuracy: 0.3750 - val_loss: 11.0710 - val_accuracy: 0.1000 - 11s/epoch - 11s/step\n",
      "Epoch 587/1000\n",
      "1/1 - 8s - loss: 1.8880 - accuracy: 0.3000 - val_loss: 11.1993 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 588/1000\n",
      "1/1 - 8s - loss: 1.7790 - accuracy: 0.3250 - val_loss: 11.1864 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 589/1000\n",
      "1/1 - 9s - loss: 1.6311 - accuracy: 0.3500 - val_loss: 11.0535 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 590/1000\n",
      "1/1 - 9s - loss: 1.5438 - accuracy: 0.4500 - val_loss: 10.9439 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 591/1000\n",
      "1/1 - 10s - loss: 1.2625 - accuracy: 0.4250 - val_loss: 10.8374 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 592/1000\n",
      "1/1 - 14s - loss: 1.5527 - accuracy: 0.4250 - val_loss: 10.6938 - val_accuracy: 0.0750 - 14s/epoch - 14s/step\n",
      "Epoch 593/1000\n",
      "1/1 - 13s - loss: 1.6340 - accuracy: 0.4000 - val_loss: 10.5501 - val_accuracy: 0.0750 - 13s/epoch - 13s/step\n",
      "Epoch 594/1000\n",
      "1/1 - 9s - loss: 1.4350 - accuracy: 0.5250 - val_loss: 10.4411 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 595/1000\n",
      "1/1 - 8s - loss: 1.5372 - accuracy: 0.4500 - val_loss: 10.3700 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 596/1000\n",
      "1/1 - 9s - loss: 1.6773 - accuracy: 0.4250 - val_loss: 10.3340 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 597/1000\n",
      "1/1 - 9s - loss: 1.3449 - accuracy: 0.4000 - val_loss: 10.3035 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 598/1000\n",
      "1/1 - 8s - loss: 1.7893 - accuracy: 0.2750 - val_loss: 10.1972 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 599/1000\n",
      "1/1 - 10s - loss: 1.7415 - accuracy: 0.3750 - val_loss: 10.1559 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 600/1000\n",
      "1/1 - 11s - loss: 1.5263 - accuracy: 0.3750 - val_loss: 10.0966 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 601/1000\n",
      "1/1 - 10s - loss: 1.8252 - accuracy: 0.2750 - val_loss: 9.9532 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 602/1000\n",
      "1/1 - 8s - loss: 1.2090 - accuracy: 0.5000 - val_loss: 9.8850 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 603/1000\n",
      "1/1 - 9s - loss: 1.2764 - accuracy: 0.5500 - val_loss: 9.8818 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 604/1000\n",
      "1/1 - 8s - loss: 1.3665 - accuracy: 0.4750 - val_loss: 9.8712 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 605/1000\n",
      "1/1 - 9s - loss: 1.3818 - accuracy: 0.5000 - val_loss: 9.9365 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 606/1000\n",
      "1/1 - 9s - loss: 1.6857 - accuracy: 0.3500 - val_loss: 10.0901 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 607/1000\n",
      "1/1 - 9s - loss: 1.5145 - accuracy: 0.4000 - val_loss: 10.1972 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 608/1000\n",
      "1/1 - 9s - loss: 1.5410 - accuracy: 0.3250 - val_loss: 10.1644 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 609/1000\n",
      "1/1 - 9s - loss: 1.6983 - accuracy: 0.4000 - val_loss: 10.1997 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 610/1000\n",
      "1/1 - 8s - loss: 1.8390 - accuracy: 0.2250 - val_loss: 10.3072 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 611/1000\n",
      "1/1 - 9s - loss: 1.7787 - accuracy: 0.3000 - val_loss: 10.4479 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 612/1000\n",
      "1/1 - 9s - loss: 1.2988 - accuracy: 0.5000 - val_loss: 10.5850 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 613/1000\n",
      "1/1 - 8s - loss: 1.5636 - accuracy: 0.4000 - val_loss: 10.9695 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 614/1000\n",
      "1/1 - 9s - loss: 1.7153 - accuracy: 0.3500 - val_loss: 11.3654 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 615/1000\n",
      "1/1 - 9s - loss: 1.5510 - accuracy: 0.3500 - val_loss: 11.5327 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 616/1000\n",
      "1/1 - 9s - loss: 1.6156 - accuracy: 0.3000 - val_loss: 11.3093 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 617/1000\n",
      "1/1 - 11s - loss: 1.4673 - accuracy: 0.4500 - val_loss: 11.1665 - val_accuracy: 0.0250 - 11s/epoch - 11s/step\n",
      "Epoch 618/1000\n",
      "1/1 - 8s - loss: 1.7936 - accuracy: 0.3750 - val_loss: 11.1230 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 619/1000\n",
      "1/1 - 8s - loss: 2.0332 - accuracy: 0.2250 - val_loss: 11.1845 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 620/1000\n",
      "1/1 - 8s - loss: 1.6438 - accuracy: 0.3000 - val_loss: 11.1687 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 621/1000\n",
      "1/1 - 8s - loss: 1.9125 - accuracy: 0.2500 - val_loss: 11.1135 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 622/1000\n",
      "1/1 - 9s - loss: 1.7703 - accuracy: 0.3750 - val_loss: 11.0449 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 623/1000\n",
      "1/1 - 9s - loss: 1.4667 - accuracy: 0.4750 - val_loss: 11.1219 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1000\n",
      "1/1 - 9s - loss: 1.5939 - accuracy: 0.3500 - val_loss: 11.1905 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 625/1000\n",
      "1/1 - 8s - loss: 1.2029 - accuracy: 0.5000 - val_loss: 11.3696 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 626/1000\n",
      "1/1 - 8s - loss: 1.7589 - accuracy: 0.3250 - val_loss: 11.3977 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 627/1000\n",
      "1/1 - 8s - loss: 1.7826 - accuracy: 0.3250 - val_loss: 11.3771 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 628/1000\n",
      "1/1 - 9s - loss: 1.5746 - accuracy: 0.3750 - val_loss: 11.3847 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 629/1000\n",
      "1/1 - 9s - loss: 1.6904 - accuracy: 0.3750 - val_loss: 11.3613 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 630/1000\n",
      "1/1 - 9s - loss: 1.8439 - accuracy: 0.2250 - val_loss: 11.2796 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 631/1000\n",
      "1/1 - 8s - loss: 1.6860 - accuracy: 0.3500 - val_loss: 11.2381 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 632/1000\n",
      "1/1 - 8s - loss: 2.0957 - accuracy: 0.2250 - val_loss: 11.1069 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 633/1000\n",
      "1/1 - 8s - loss: 1.6531 - accuracy: 0.3250 - val_loss: 10.9632 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 634/1000\n",
      "1/1 - 8s - loss: 1.4903 - accuracy: 0.4250 - val_loss: 10.6263 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 635/1000\n",
      "1/1 - 8s - loss: 1.6394 - accuracy: 0.4000 - val_loss: 10.4722 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 636/1000\n",
      "1/1 - 9s - loss: 2.0441 - accuracy: 0.3500 - val_loss: 10.3933 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 637/1000\n",
      "1/1 - 8s - loss: 1.6187 - accuracy: 0.4000 - val_loss: 10.4016 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 638/1000\n",
      "1/1 - 8s - loss: 1.7139 - accuracy: 0.3750 - val_loss: 10.4543 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 639/1000\n",
      "1/1 - 11s - loss: 1.8933 - accuracy: 0.2750 - val_loss: 10.5307 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 640/1000\n",
      "1/1 - 8s - loss: 1.3514 - accuracy: 0.4500 - val_loss: 10.8168 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 641/1000\n",
      "1/1 - 9s - loss: 1.7600 - accuracy: 0.3750 - val_loss: 11.0992 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 642/1000\n",
      "1/1 - 8s - loss: 1.5430 - accuracy: 0.3500 - val_loss: 11.3699 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 643/1000\n",
      "1/1 - 11s - loss: 1.5399 - accuracy: 0.3000 - val_loss: 11.5007 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 644/1000\n",
      "1/1 - 8s - loss: 1.5902 - accuracy: 0.2250 - val_loss: 11.5525 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 645/1000\n",
      "1/1 - 9s - loss: 1.7502 - accuracy: 0.2250 - val_loss: 11.2741 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 646/1000\n",
      "1/1 - 8s - loss: 1.8442 - accuracy: 0.2500 - val_loss: 10.8590 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 647/1000\n",
      "1/1 - 9s - loss: 1.3233 - accuracy: 0.4750 - val_loss: 10.5244 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 648/1000\n",
      "1/1 - 8s - loss: 1.3263 - accuracy: 0.4500 - val_loss: 10.3208 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 649/1000\n",
      "1/1 - 10s - loss: 1.6351 - accuracy: 0.3500 - val_loss: 10.1707 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 650/1000\n",
      "1/1 - 8s - loss: 1.4163 - accuracy: 0.4000 - val_loss: 10.2925 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 651/1000\n",
      "1/1 - 9s - loss: 1.5985 - accuracy: 0.3500 - val_loss: 10.4492 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 652/1000\n",
      "1/1 - 10s - loss: 1.2948 - accuracy: 0.4750 - val_loss: 10.6719 - val_accuracy: 0.0750 - 10s/epoch - 10s/step\n",
      "Epoch 653/1000\n",
      "1/1 - 8s - loss: 1.6707 - accuracy: 0.3750 - val_loss: 10.9239 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 654/1000\n",
      "1/1 - 7s - loss: 1.3568 - accuracy: 0.4500 - val_loss: 11.2775 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 655/1000\n",
      "1/1 - 9s - loss: 1.6640 - accuracy: 0.3000 - val_loss: 11.5814 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 656/1000\n",
      "1/1 - 8s - loss: 1.5053 - accuracy: 0.4750 - val_loss: 11.9645 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 657/1000\n",
      "1/1 - 10s - loss: 1.4713 - accuracy: 0.5000 - val_loss: 12.3989 - val_accuracy: 0.1000 - 10s/epoch - 10s/step\n",
      "Epoch 658/1000\n",
      "1/1 - 9s - loss: 1.7422 - accuracy: 0.3000 - val_loss: 12.3723 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 659/1000\n",
      "1/1 - 9s - loss: 1.6225 - accuracy: 0.3000 - val_loss: 12.2085 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 660/1000\n",
      "1/1 - 8s - loss: 1.5146 - accuracy: 0.4250 - val_loss: 11.8646 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 661/1000\n",
      "1/1 - 8s - loss: 1.3304 - accuracy: 0.5000 - val_loss: 11.8124 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 662/1000\n",
      "1/1 - 8s - loss: 1.5126 - accuracy: 0.4250 - val_loss: 11.7388 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 663/1000\n",
      "1/1 - 8s - loss: 1.5902 - accuracy: 0.4000 - val_loss: 11.7437 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 664/1000\n",
      "1/1 - 8s - loss: 1.2915 - accuracy: 0.5250 - val_loss: 11.8281 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 665/1000\n",
      "1/1 - 8s - loss: 1.8161 - accuracy: 0.3000 - val_loss: 12.1858 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 666/1000\n",
      "1/1 - 8s - loss: 1.5160 - accuracy: 0.3250 - val_loss: 12.2012 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 667/1000\n",
      "1/1 - 9s - loss: 1.7692 - accuracy: 0.3250 - val_loss: 12.1513 - val_accuracy: 0.1000 - 9s/epoch - 9s/step\n",
      "Epoch 668/1000\n",
      "1/1 - 8s - loss: 1.4634 - accuracy: 0.4000 - val_loss: 12.1391 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 669/1000\n",
      "1/1 - 9s - loss: 1.1482 - accuracy: 0.6000 - val_loss: 12.1310 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 670/1000\n",
      "1/1 - 9s - loss: 1.6911 - accuracy: 0.4250 - val_loss: 12.1183 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 671/1000\n",
      "1/1 - 8s - loss: 1.6206 - accuracy: 0.3750 - val_loss: 11.9533 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 672/1000\n",
      "1/1 - 9s - loss: 1.5164 - accuracy: 0.4250 - val_loss: 11.7820 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 673/1000\n",
      "1/1 - 9s - loss: 1.4305 - accuracy: 0.4750 - val_loss: 11.6257 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 674/1000\n",
      "1/1 - 9s - loss: 1.6093 - accuracy: 0.4000 - val_loss: 11.5556 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 675/1000\n",
      "1/1 - 11s - loss: 1.5728 - accuracy: 0.4250 - val_loss: 11.6226 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 676/1000\n",
      "1/1 - 8s - loss: 1.6573 - accuracy: 0.4750 - val_loss: 11.7256 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 677/1000\n",
      "1/1 - 8s - loss: 1.7738 - accuracy: 0.4000 - val_loss: 11.8043 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 678/1000\n",
      "1/1 - 8s - loss: 1.6123 - accuracy: 0.4500 - val_loss: 12.1853 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 679/1000\n",
      "1/1 - 9s - loss: 1.6041 - accuracy: 0.4000 - val_loss: 12.5478 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 680/1000\n",
      "1/1 - 11s - loss: 1.6083 - accuracy: 0.4500 - val_loss: 12.5687 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 681/1000\n",
      "1/1 - 9s - loss: 1.3513 - accuracy: 0.4500 - val_loss: 12.3412 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 682/1000\n",
      "1/1 - 8s - loss: 1.2528 - accuracy: 0.5250 - val_loss: 12.1560 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 683/1000\n",
      "1/1 - 8s - loss: 1.9338 - accuracy: 0.3000 - val_loss: 11.7109 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 684/1000\n",
      "1/1 - 8s - loss: 1.6871 - accuracy: 0.3000 - val_loss: 11.6216 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 685/1000\n",
      "1/1 - 8s - loss: 1.7390 - accuracy: 0.3500 - val_loss: 11.4464 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 686/1000\n",
      "1/1 - 7s - loss: 1.8542 - accuracy: 0.3000 - val_loss: 11.3461 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 687/1000\n",
      "1/1 - 9s - loss: 1.3730 - accuracy: 0.4500 - val_loss: 11.2503 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 688/1000\n",
      "1/1 - 11s - loss: 1.6975 - accuracy: 0.3750 - val_loss: 11.2298 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 689/1000\n",
      "1/1 - 8s - loss: 1.6157 - accuracy: 0.4000 - val_loss: 11.2984 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 690/1000\n",
      "1/1 - 8s - loss: 1.3842 - accuracy: 0.4750 - val_loss: 11.4721 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "1/1 - 8s - loss: 1.8014 - accuracy: 0.3000 - val_loss: 11.4986 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 692/1000\n",
      "1/1 - 8s - loss: 1.5582 - accuracy: 0.4250 - val_loss: 11.5547 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 693/1000\n",
      "1/1 - 8s - loss: 1.5616 - accuracy: 0.4500 - val_loss: 11.5523 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 694/1000\n",
      "1/1 - 9s - loss: 1.4617 - accuracy: 0.4250 - val_loss: 11.4172 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 695/1000\n",
      "1/1 - 10s - loss: 1.8219 - accuracy: 0.3750 - val_loss: 11.2703 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 696/1000\n",
      "1/1 - 9s - loss: 1.6373 - accuracy: 0.3750 - val_loss: 11.2747 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 697/1000\n",
      "1/1 - 9s - loss: 1.9325 - accuracy: 0.2750 - val_loss: 11.2730 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 698/1000\n",
      "1/1 - 9s - loss: 1.4898 - accuracy: 0.4750 - val_loss: 11.3950 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 699/1000\n",
      "1/1 - 9s - loss: 1.4322 - accuracy: 0.5000 - val_loss: 11.4857 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 700/1000\n",
      "1/1 - 11s - loss: 1.3347 - accuracy: 0.5000 - val_loss: 11.6268 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 701/1000\n",
      "1/1 - 15s - loss: 1.6432 - accuracy: 0.3750 - val_loss: 11.8049 - val_accuracy: 0.0500 - 15s/epoch - 15s/step\n",
      "Epoch 702/1000\n",
      "1/1 - 15s - loss: 1.5477 - accuracy: 0.4250 - val_loss: 11.9316 - val_accuracy: 0.0500 - 15s/epoch - 15s/step\n",
      "Epoch 703/1000\n",
      "1/1 - 15s - loss: 1.4404 - accuracy: 0.4750 - val_loss: 12.0049 - val_accuracy: 0.0500 - 15s/epoch - 15s/step\n",
      "Epoch 704/1000\n",
      "1/1 - 11s - loss: 1.5496 - accuracy: 0.3500 - val_loss: 11.9452 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 705/1000\n",
      "1/1 - 9s - loss: 1.3797 - accuracy: 0.5250 - val_loss: 11.7675 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 706/1000\n",
      "1/1 - 9s - loss: 1.7279 - accuracy: 0.4000 - val_loss: 11.4933 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 707/1000\n",
      "1/1 - 8s - loss: 1.4499 - accuracy: 0.5250 - val_loss: 11.3180 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 708/1000\n",
      "1/1 - 9s - loss: 1.2635 - accuracy: 0.4750 - val_loss: 11.2672 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 709/1000\n",
      "1/1 - 9s - loss: 1.6067 - accuracy: 0.4500 - val_loss: 11.3378 - val_accuracy: 0.0750 - 9s/epoch - 9s/step\n",
      "Epoch 710/1000\n",
      "1/1 - 11s - loss: 1.7169 - accuracy: 0.3250 - val_loss: 11.6533 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 711/1000\n",
      "1/1 - 13s - loss: 1.6859 - accuracy: 0.3750 - val_loss: 12.0188 - val_accuracy: 0.0500 - 13s/epoch - 13s/step\n",
      "Epoch 712/1000\n",
      "1/1 - 12s - loss: 1.4867 - accuracy: 0.4000 - val_loss: 12.2714 - val_accuracy: 0.0500 - 12s/epoch - 12s/step\n",
      "Epoch 713/1000\n",
      "1/1 - 12s - loss: 1.1936 - accuracy: 0.5500 - val_loss: 12.5299 - val_accuracy: 0.0500 - 12s/epoch - 12s/step\n",
      "Epoch 714/1000\n",
      "1/1 - 11s - loss: 1.5523 - accuracy: 0.3500 - val_loss: 12.5137 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 715/1000\n",
      "1/1 - 11s - loss: 1.2321 - accuracy: 0.5250 - val_loss: 12.5375 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 716/1000\n",
      "1/1 - 10s - loss: 1.5235 - accuracy: 0.4500 - val_loss: 12.4589 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 717/1000\n",
      "1/1 - 10s - loss: 1.6474 - accuracy: 0.3000 - val_loss: 12.1394 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 718/1000\n",
      "1/1 - 10s - loss: 1.6731 - accuracy: 0.3500 - val_loss: 11.9096 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 719/1000\n",
      "1/1 - 10s - loss: 1.6063 - accuracy: 0.4250 - val_loss: 11.6904 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 720/1000\n",
      "1/1 - 12s - loss: 1.7862 - accuracy: 0.3250 - val_loss: 11.4554 - val_accuracy: 0.0500 - 12s/epoch - 12s/step\n",
      "Epoch 721/1000\n",
      "1/1 - 11s - loss: 1.7665 - accuracy: 0.3500 - val_loss: 11.2726 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 722/1000\n",
      "1/1 - 11s - loss: 1.6936 - accuracy: 0.3750 - val_loss: 11.0995 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 723/1000\n",
      "1/1 - 12s - loss: 1.3420 - accuracy: 0.4500 - val_loss: 10.9909 - val_accuracy: 0.0500 - 12s/epoch - 12s/step\n",
      "Epoch 724/1000\n",
      "1/1 - 11s - loss: 1.3886 - accuracy: 0.4500 - val_loss: 11.0480 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 725/1000\n",
      "1/1 - 11s - loss: 1.5634 - accuracy: 0.4250 - val_loss: 11.1450 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 726/1000\n",
      "1/1 - 11s - loss: 1.2863 - accuracy: 0.4500 - val_loss: 11.3090 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 727/1000\n",
      "1/1 - 12s - loss: 1.7984 - accuracy: 0.2750 - val_loss: 11.4007 - val_accuracy: 0.0750 - 12s/epoch - 12s/step\n",
      "Epoch 728/1000\n",
      "1/1 - 11s - loss: 1.4458 - accuracy: 0.4000 - val_loss: 11.6709 - val_accuracy: 0.0750 - 11s/epoch - 11s/step\n",
      "Epoch 729/1000\n",
      "1/1 - 11s - loss: 1.2400 - accuracy: 0.5250 - val_loss: 11.9036 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 730/1000\n",
      "1/1 - 10s - loss: 1.4564 - accuracy: 0.4500 - val_loss: 12.0855 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 731/1000\n",
      "1/1 - 10s - loss: 1.5738 - accuracy: 0.3500 - val_loss: 12.1707 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 732/1000\n",
      "1/1 - 10s - loss: 1.7129 - accuracy: 0.3500 - val_loss: 12.2645 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 733/1000\n",
      "1/1 - 10s - loss: 1.5675 - accuracy: 0.4750 - val_loss: 12.3263 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 734/1000\n",
      "1/1 - 10s - loss: 1.6208 - accuracy: 0.3750 - val_loss: 12.3392 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 735/1000\n",
      "1/1 - 11s - loss: 1.5108 - accuracy: 0.4000 - val_loss: 12.2791 - val_accuracy: 0.0500 - 11s/epoch - 11s/step\n",
      "Epoch 736/1000\n",
      "1/1 - 10s - loss: 1.7584 - accuracy: 0.3250 - val_loss: 12.2216 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 737/1000\n",
      "1/1 - 10s - loss: 1.5622 - accuracy: 0.4250 - val_loss: 12.6475 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 738/1000\n",
      "1/1 - 10s - loss: 1.4622 - accuracy: 0.4250 - val_loss: 13.0663 - val_accuracy: 0.0250 - 10s/epoch - 10s/step\n",
      "Epoch 739/1000\n",
      "1/1 - 9s - loss: 1.7473 - accuracy: 0.4000 - val_loss: 13.3461 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 740/1000\n",
      "1/1 - 9s - loss: 1.6540 - accuracy: 0.4000 - val_loss: 13.4569 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 741/1000\n",
      "1/1 - 7s - loss: 1.7109 - accuracy: 0.3250 - val_loss: 13.5024 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 742/1000\n",
      "1/1 - 7s - loss: 1.4599 - accuracy: 0.4250 - val_loss: 13.4260 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 743/1000\n",
      "1/1 - 7s - loss: 1.4091 - accuracy: 0.4750 - val_loss: 13.3178 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 744/1000\n",
      "1/1 - 7s - loss: 1.5667 - accuracy: 0.4500 - val_loss: 13.1636 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 745/1000\n",
      "1/1 - 8s - loss: 1.6241 - accuracy: 0.3750 - val_loss: 12.7913 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 746/1000\n",
      "1/1 - 8s - loss: 1.3303 - accuracy: 0.4750 - val_loss: 13.0494 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 747/1000\n",
      "1/1 - 9s - loss: 1.4566 - accuracy: 0.4250 - val_loss: 13.3136 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 748/1000\n",
      "1/1 - 9s - loss: 1.3508 - accuracy: 0.4250 - val_loss: 13.4762 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 749/1000\n",
      "1/1 - 8s - loss: 1.6411 - accuracy: 0.3500 - val_loss: 13.4676 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 750/1000\n",
      "1/1 - 10s - loss: 1.4099 - accuracy: 0.4250 - val_loss: 13.5001 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 751/1000\n",
      "1/1 - 10s - loss: 1.6834 - accuracy: 0.3250 - val_loss: 13.5335 - val_accuracy: 0.0500 - 10s/epoch - 10s/step\n",
      "Epoch 752/1000\n",
      "1/1 - 9s - loss: 2.0120 - accuracy: 0.2750 - val_loss: 13.5224 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 753/1000\n",
      "1/1 - 8s - loss: 1.1591 - accuracy: 0.5500 - val_loss: 13.5961 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 754/1000\n",
      "1/1 - 8s - loss: 1.5175 - accuracy: 0.4250 - val_loss: 13.6507 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 755/1000\n",
      "1/1 - 9s - loss: 1.7022 - accuracy: 0.2750 - val_loss: 13.6820 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 756/1000\n",
      "1/1 - 7s - loss: 1.4378 - accuracy: 0.4500 - val_loss: 13.7102 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 757/1000\n",
      "1/1 - 7s - loss: 1.7355 - accuracy: 0.3000 - val_loss: 13.5664 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "1/1 - 7s - loss: 1.7212 - accuracy: 0.3500 - val_loss: 13.4175 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 759/1000\n",
      "1/1 - 8s - loss: 1.5817 - accuracy: 0.4000 - val_loss: 13.2623 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 760/1000\n",
      "1/1 - 7s - loss: 1.5577 - accuracy: 0.4000 - val_loss: 13.0744 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 761/1000\n",
      "1/1 - 7s - loss: 1.9403 - accuracy: 0.3500 - val_loss: 12.8119 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 762/1000\n",
      "1/1 - 8s - loss: 1.9146 - accuracy: 0.2750 - val_loss: 12.1370 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 763/1000\n",
      "1/1 - 8s - loss: 1.2925 - accuracy: 0.5000 - val_loss: 11.6723 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 764/1000\n",
      "1/1 - 8s - loss: 1.5965 - accuracy: 0.4250 - val_loss: 11.5537 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 765/1000\n",
      "1/1 - 7s - loss: 1.5397 - accuracy: 0.4500 - val_loss: 11.5498 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 766/1000\n",
      "1/1 - 8s - loss: 1.3489 - accuracy: 0.4750 - val_loss: 11.6217 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 767/1000\n",
      "1/1 - 7s - loss: 1.6143 - accuracy: 0.3750 - val_loss: 12.0490 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 768/1000\n",
      "1/1 - 7s - loss: 1.7601 - accuracy: 0.4000 - val_loss: 12.5282 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 769/1000\n",
      "1/1 - 7s - loss: 1.3570 - accuracy: 0.4750 - val_loss: 12.6054 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 770/1000\n",
      "1/1 - 8s - loss: 1.4936 - accuracy: 0.4500 - val_loss: 12.7944 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 771/1000\n",
      "1/1 - 7s - loss: 1.4627 - accuracy: 0.3750 - val_loss: 13.0671 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 772/1000\n",
      "1/1 - 8s - loss: 1.4866 - accuracy: 0.3750 - val_loss: 13.2864 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 773/1000\n",
      "1/1 - 8s - loss: 1.3700 - accuracy: 0.4500 - val_loss: 13.4545 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 774/1000\n",
      "1/1 - 7s - loss: 1.5185 - accuracy: 0.4000 - val_loss: 13.7548 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 775/1000\n",
      "1/1 - 8s - loss: 1.1226 - accuracy: 0.5500 - val_loss: 14.0209 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 776/1000\n",
      "1/1 - 8s - loss: 1.2549 - accuracy: 0.5000 - val_loss: 14.0815 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 777/1000\n",
      "1/1 - 7s - loss: 1.5498 - accuracy: 0.3500 - val_loss: 14.1333 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 778/1000\n",
      "1/1 - 9s - loss: 1.6286 - accuracy: 0.3250 - val_loss: 14.0383 - val_accuracy: 0.0250 - 9s/epoch - 9s/step\n",
      "Epoch 779/1000\n",
      "1/1 - 8s - loss: 1.5644 - accuracy: 0.3250 - val_loss: 13.7979 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 780/1000\n",
      "1/1 - 8s - loss: 1.5461 - accuracy: 0.4000 - val_loss: 13.1065 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 781/1000\n",
      "1/1 - 8s - loss: 1.5676 - accuracy: 0.3250 - val_loss: 12.5456 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 782/1000\n",
      "1/1 - 8s - loss: 1.5979 - accuracy: 0.4500 - val_loss: 12.0743 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 783/1000\n",
      "1/1 - 7s - loss: 1.4912 - accuracy: 0.4750 - val_loss: 12.0348 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 784/1000\n",
      "1/1 - 7s - loss: 1.9690 - accuracy: 0.2250 - val_loss: 12.0232 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 785/1000\n",
      "1/1 - 7s - loss: 1.7424 - accuracy: 0.3750 - val_loss: 12.1945 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 786/1000\n",
      "1/1 - 8s - loss: 1.7408 - accuracy: 0.3750 - val_loss: 12.5391 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 787/1000\n",
      "1/1 - 8s - loss: 1.4126 - accuracy: 0.5750 - val_loss: 12.9416 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 788/1000\n",
      "1/1 - 8s - loss: 1.6060 - accuracy: 0.3500 - val_loss: 13.4239 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 789/1000\n",
      "1/1 - 7s - loss: 1.3950 - accuracy: 0.4750 - val_loss: 13.6590 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 790/1000\n",
      "1/1 - 8s - loss: 1.4236 - accuracy: 0.4000 - val_loss: 13.5911 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 791/1000\n",
      "1/1 - 7s - loss: 1.4175 - accuracy: 0.4500 - val_loss: 13.1637 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 792/1000\n",
      "1/1 - 7s - loss: 1.4780 - accuracy: 0.4000 - val_loss: 12.5912 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 793/1000\n",
      "1/1 - 7s - loss: 1.6037 - accuracy: 0.4250 - val_loss: 12.2515 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 794/1000\n",
      "1/1 - 8s - loss: 1.5073 - accuracy: 0.4250 - val_loss: 12.0640 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 795/1000\n",
      "1/1 - 7s - loss: 1.5594 - accuracy: 0.4250 - val_loss: 11.9699 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 796/1000\n",
      "1/1 - 7s - loss: 1.8777 - accuracy: 0.3250 - val_loss: 11.9566 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 797/1000\n",
      "1/1 - 8s - loss: 1.6390 - accuracy: 0.3500 - val_loss: 11.9586 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 798/1000\n",
      "1/1 - 8s - loss: 1.5785 - accuracy: 0.4500 - val_loss: 12.1083 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 799/1000\n",
      "1/1 - 8s - loss: 1.5623 - accuracy: 0.3750 - val_loss: 12.3580 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 800/1000\n",
      "1/1 - 8s - loss: 1.9339 - accuracy: 0.2000 - val_loss: 12.6837 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 801/1000\n",
      "1/1 - 8s - loss: 1.7112 - accuracy: 0.4750 - val_loss: 13.0629 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 802/1000\n",
      "1/1 - 8s - loss: 1.7395 - accuracy: 0.3750 - val_loss: 13.4352 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 803/1000\n",
      "1/1 - 8s - loss: 1.6446 - accuracy: 0.3750 - val_loss: 13.7682 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 804/1000\n",
      "1/1 - 7s - loss: 1.5306 - accuracy: 0.5250 - val_loss: 14.0109 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 805/1000\n",
      "1/1 - 8s - loss: 1.2072 - accuracy: 0.5250 - val_loss: 14.2009 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 806/1000\n",
      "1/1 - 9s - loss: 1.3428 - accuracy: 0.5250 - val_loss: 14.6942 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 807/1000\n",
      "1/1 - 8s - loss: 1.2380 - accuracy: 0.5000 - val_loss: 14.7625 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 808/1000\n",
      "1/1 - 8s - loss: 1.5357 - accuracy: 0.4500 - val_loss: 14.5729 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 809/1000\n",
      "1/1 - 8s - loss: 1.8042 - accuracy: 0.3750 - val_loss: 14.3931 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 810/1000\n",
      "1/1 - 7s - loss: 1.3064 - accuracy: 0.5750 - val_loss: 14.1832 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 811/1000\n",
      "1/1 - 7s - loss: 1.3015 - accuracy: 0.5250 - val_loss: 13.9825 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 812/1000\n",
      "1/1 - 7s - loss: 1.5893 - accuracy: 0.3750 - val_loss: 13.5955 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 813/1000\n",
      "1/1 - 7s - loss: 1.8596 - accuracy: 0.3250 - val_loss: 13.0960 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 814/1000\n",
      "1/1 - 7s - loss: 1.4990 - accuracy: 0.4500 - val_loss: 12.5864 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 815/1000\n",
      "1/1 - 7s - loss: 1.6522 - accuracy: 0.3500 - val_loss: 12.1869 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 816/1000\n",
      "1/1 - 8s - loss: 1.4507 - accuracy: 0.3750 - val_loss: 11.7694 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 817/1000\n",
      "1/1 - 7s - loss: 1.6616 - accuracy: 0.3000 - val_loss: 11.3021 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 818/1000\n",
      "1/1 - 7s - loss: 1.9071 - accuracy: 0.2750 - val_loss: 11.0423 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 819/1000\n",
      "1/1 - 7s - loss: 1.5077 - accuracy: 0.4000 - val_loss: 10.9590 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 820/1000\n",
      "1/1 - 7s - loss: 1.5317 - accuracy: 0.4750 - val_loss: 11.2096 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 821/1000\n",
      "1/1 - 7s - loss: 1.6710 - accuracy: 0.4250 - val_loss: 11.5133 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 822/1000\n",
      "1/1 - 7s - loss: 1.4829 - accuracy: 0.3750 - val_loss: 11.8210 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 823/1000\n",
      "1/1 - 7s - loss: 1.4430 - accuracy: 0.4750 - val_loss: 12.0753 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 824/1000\n",
      "1/1 - 7s - loss: 1.7242 - accuracy: 0.3750 - val_loss: 12.1154 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 825/1000\n",
      "1/1 - 8s - loss: 1.3716 - accuracy: 0.4750 - val_loss: 12.1731 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "1/1 - 7s - loss: 1.6886 - accuracy: 0.4000 - val_loss: 12.2389 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 827/1000\n",
      "1/1 - 7s - loss: 1.4656 - accuracy: 0.4500 - val_loss: 12.3445 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 828/1000\n",
      "1/1 - 7s - loss: 1.3128 - accuracy: 0.5000 - val_loss: 12.4938 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 829/1000\n",
      "1/1 - 7s - loss: 1.6850 - accuracy: 0.4000 - val_loss: 12.5712 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 830/1000\n",
      "1/1 - 7s - loss: 1.6666 - accuracy: 0.4000 - val_loss: 12.8197 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 831/1000\n",
      "1/1 - 7s - loss: 1.1432 - accuracy: 0.6500 - val_loss: 13.1572 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 832/1000\n",
      "1/1 - 7s - loss: 1.4634 - accuracy: 0.4750 - val_loss: 13.4834 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 833/1000\n",
      "1/1 - 8s - loss: 1.4012 - accuracy: 0.5000 - val_loss: 13.7837 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 834/1000\n",
      "1/1 - 7s - loss: 1.7476 - accuracy: 0.3250 - val_loss: 13.7796 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 835/1000\n",
      "1/1 - 8s - loss: 1.4304 - accuracy: 0.4250 - val_loss: 13.8082 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 836/1000\n",
      "1/1 - 8s - loss: 1.7626 - accuracy: 0.4000 - val_loss: 13.8384 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 837/1000\n",
      "1/1 - 7s - loss: 1.9053 - accuracy: 0.3500 - val_loss: 13.7816 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 838/1000\n",
      "1/1 - 7s - loss: 1.4711 - accuracy: 0.3750 - val_loss: 13.6283 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 839/1000\n",
      "1/1 - 7s - loss: 1.2966 - accuracy: 0.4750 - val_loss: 13.4375 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 840/1000\n",
      "1/1 - 7s - loss: 1.6790 - accuracy: 0.4250 - val_loss: 13.2489 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 841/1000\n",
      "1/1 - 7s - loss: 1.3099 - accuracy: 0.5000 - val_loss: 13.0354 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 842/1000\n",
      "1/1 - 7s - loss: 1.5538 - accuracy: 0.4500 - val_loss: 12.8351 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 843/1000\n",
      "1/1 - 8s - loss: 1.5334 - accuracy: 0.3750 - val_loss: 12.6673 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 844/1000\n",
      "1/1 - 8s - loss: 1.6456 - accuracy: 0.4250 - val_loss: 12.6273 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 845/1000\n",
      "1/1 - 7s - loss: 1.6426 - accuracy: 0.3750 - val_loss: 12.5790 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 846/1000\n",
      "1/1 - 7s - loss: 1.5480 - accuracy: 0.3750 - val_loss: 12.4642 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 847/1000\n",
      "1/1 - 7s - loss: 1.6262 - accuracy: 0.4000 - val_loss: 12.3571 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 848/1000\n",
      "1/1 - 8s - loss: 1.6207 - accuracy: 0.4000 - val_loss: 12.3833 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 849/1000\n",
      "1/1 - 7s - loss: 1.5529 - accuracy: 0.4250 - val_loss: 12.4726 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 850/1000\n",
      "1/1 - 7s - loss: 1.6941 - accuracy: 0.3250 - val_loss: 12.5614 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 851/1000\n",
      "1/1 - 7s - loss: 1.3891 - accuracy: 0.4500 - val_loss: 12.6615 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 852/1000\n",
      "1/1 - 8s - loss: 1.4842 - accuracy: 0.3750 - val_loss: 12.7504 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 853/1000\n",
      "1/1 - 7s - loss: 1.5949 - accuracy: 0.4000 - val_loss: 12.8735 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 854/1000\n",
      "1/1 - 7s - loss: 1.3156 - accuracy: 0.4500 - val_loss: 12.9401 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 855/1000\n",
      "1/1 - 7s - loss: 1.4779 - accuracy: 0.4500 - val_loss: 13.0504 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 856/1000\n",
      "1/1 - 7s - loss: 1.5854 - accuracy: 0.3750 - val_loss: 13.1207 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 857/1000\n",
      "1/1 - 8s - loss: 1.3548 - accuracy: 0.5250 - val_loss: 13.2269 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 858/1000\n",
      "1/1 - 7s - loss: 1.6107 - accuracy: 0.3250 - val_loss: 13.1829 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 859/1000\n",
      "1/1 - 8s - loss: 1.4996 - accuracy: 0.4750 - val_loss: 13.2077 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 860/1000\n",
      "1/1 - 7s - loss: 1.4159 - accuracy: 0.5000 - val_loss: 13.2333 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 861/1000\n",
      "1/1 - 8s - loss: 1.5831 - accuracy: 0.4250 - val_loss: 12.9039 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 862/1000\n",
      "1/1 - 7s - loss: 1.5358 - accuracy: 0.4000 - val_loss: 12.4995 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 863/1000\n",
      "1/1 - 8s - loss: 1.5228 - accuracy: 0.4750 - val_loss: 12.2637 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 864/1000\n",
      "1/1 - 7s - loss: 1.6991 - accuracy: 0.4000 - val_loss: 12.1385 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 865/1000\n",
      "1/1 - 8s - loss: 1.3059 - accuracy: 0.4750 - val_loss: 12.0631 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 866/1000\n",
      "1/1 - 8s - loss: 1.4571 - accuracy: 0.4500 - val_loss: 12.0436 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 867/1000\n",
      "1/1 - 8s - loss: 1.5338 - accuracy: 0.4750 - val_loss: 12.0340 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 868/1000\n",
      "1/1 - 7s - loss: 1.3821 - accuracy: 0.4750 - val_loss: 12.0396 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 869/1000\n",
      "1/1 - 8s - loss: 1.4288 - accuracy: 0.4750 - val_loss: 12.6543 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 870/1000\n",
      "1/1 - 8s - loss: 1.1931 - accuracy: 0.5250 - val_loss: 13.4834 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 871/1000\n",
      "1/1 - 7s - loss: 1.5848 - accuracy: 0.4000 - val_loss: 14.3466 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 872/1000\n",
      "1/1 - 9s - loss: 1.0915 - accuracy: 0.6000 - val_loss: 15.1425 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 873/1000\n",
      "1/1 - 8s - loss: 1.4763 - accuracy: 0.3750 - val_loss: 15.8431 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 874/1000\n",
      "1/1 - 7s - loss: 1.4327 - accuracy: 0.4250 - val_loss: 15.9396 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 875/1000\n",
      "1/1 - 7s - loss: 1.5275 - accuracy: 0.4250 - val_loss: 15.7260 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 876/1000\n",
      "1/1 - 8s - loss: 1.4239 - accuracy: 0.5000 - val_loss: 15.3634 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 877/1000\n",
      "1/1 - 8s - loss: 1.4405 - accuracy: 0.4500 - val_loss: 14.7825 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 878/1000\n",
      "1/1 - 8s - loss: 1.3800 - accuracy: 0.5000 - val_loss: 14.2045 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 879/1000\n",
      "1/1 - 7s - loss: 1.4421 - accuracy: 0.5250 - val_loss: 13.9418 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 880/1000\n",
      "1/1 - 7s - loss: 1.4817 - accuracy: 0.4500 - val_loss: 13.4503 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 881/1000\n",
      "1/1 - 7s - loss: 1.7234 - accuracy: 0.4250 - val_loss: 12.9052 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 882/1000\n",
      "1/1 - 7s - loss: 1.5026 - accuracy: 0.4750 - val_loss: 12.4488 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 883/1000\n",
      "1/1 - 7s - loss: 1.5935 - accuracy: 0.3750 - val_loss: 12.2498 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 884/1000\n",
      "1/1 - 7s - loss: 1.1843 - accuracy: 0.5250 - val_loss: 12.1576 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 885/1000\n",
      "1/1 - 7s - loss: 1.3178 - accuracy: 0.5250 - val_loss: 12.2046 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 886/1000\n",
      "1/1 - 7s - loss: 1.6222 - accuracy: 0.5000 - val_loss: 12.2566 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 887/1000\n",
      "1/1 - 8s - loss: 1.4987 - accuracy: 0.4000 - val_loss: 12.4639 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 888/1000\n",
      "1/1 - 7s - loss: 1.7456 - accuracy: 0.4000 - val_loss: 12.7186 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 889/1000\n",
      "1/1 - 8s - loss: 1.4421 - accuracy: 0.5250 - val_loss: 13.1250 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 890/1000\n",
      "1/1 - 7s - loss: 1.2578 - accuracy: 0.6000 - val_loss: 13.7020 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 891/1000\n",
      "1/1 - 7s - loss: 1.4362 - accuracy: 0.4500 - val_loss: 14.1265 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 892/1000\n",
      "1/1 - 7s - loss: 1.5768 - accuracy: 0.3750 - val_loss: 14.5035 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 893/1000\n",
      "1/1 - 7s - loss: 1.2614 - accuracy: 0.5500 - val_loss: 14.9206 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "1/1 - 7s - loss: 1.3932 - accuracy: 0.4250 - val_loss: 14.9674 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 895/1000\n",
      "1/1 - 7s - loss: 1.6274 - accuracy: 0.4000 - val_loss: 14.7783 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 896/1000\n",
      "1/1 - 7s - loss: 1.4454 - accuracy: 0.5000 - val_loss: 14.5196 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 897/1000\n",
      "1/1 - 7s - loss: 1.1140 - accuracy: 0.6500 - val_loss: 14.1602 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 898/1000\n",
      "1/1 - 7s - loss: 1.4776 - accuracy: 0.4250 - val_loss: 13.7993 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 899/1000\n",
      "1/1 - 7s - loss: 1.5788 - accuracy: 0.4250 - val_loss: 13.4341 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 900/1000\n",
      "1/1 - 7s - loss: 1.4696 - accuracy: 0.4500 - val_loss: 13.1361 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 901/1000\n",
      "1/1 - 7s - loss: 1.1992 - accuracy: 0.5750 - val_loss: 12.9672 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 902/1000\n",
      "1/1 - 7s - loss: 1.2687 - accuracy: 0.5250 - val_loss: 12.9703 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 903/1000\n",
      "1/1 - 7s - loss: 1.3440 - accuracy: 0.5000 - val_loss: 13.1083 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 904/1000\n",
      "1/1 - 7s - loss: 1.2984 - accuracy: 0.5500 - val_loss: 13.5535 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 905/1000\n",
      "1/1 - 7s - loss: 1.4326 - accuracy: 0.4750 - val_loss: 14.0275 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 906/1000\n",
      "1/1 - 7s - loss: 1.5790 - accuracy: 0.4750 - val_loss: 14.4701 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 907/1000\n",
      "1/1 - 7s - loss: 1.5055 - accuracy: 0.5000 - val_loss: 14.8453 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 908/1000\n",
      "1/1 - 7s - loss: 1.4735 - accuracy: 0.4750 - val_loss: 15.4461 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 909/1000\n",
      "1/1 - 7s - loss: 1.4693 - accuracy: 0.4250 - val_loss: 15.9163 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 910/1000\n",
      "1/1 - 7s - loss: 1.4380 - accuracy: 0.4500 - val_loss: 16.0456 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 911/1000\n",
      "1/1 - 7s - loss: 1.3286 - accuracy: 0.5250 - val_loss: 16.0667 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 912/1000\n",
      "1/1 - 7s - loss: 1.7923 - accuracy: 0.3500 - val_loss: 15.7343 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 913/1000\n",
      "1/1 - 8s - loss: 1.7158 - accuracy: 0.3500 - val_loss: 15.1692 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 914/1000\n",
      "1/1 - 9s - loss: 1.5000 - accuracy: 0.4250 - val_loss: 14.6850 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 915/1000\n",
      "1/1 - 7s - loss: 1.3429 - accuracy: 0.5250 - val_loss: 14.0824 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 916/1000\n",
      "1/1 - 8s - loss: 1.6895 - accuracy: 0.4250 - val_loss: 13.6449 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 917/1000\n",
      "1/1 - 8s - loss: 1.5774 - accuracy: 0.4250 - val_loss: 13.2514 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 918/1000\n",
      "1/1 - 7s - loss: 1.3909 - accuracy: 0.4500 - val_loss: 12.9425 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 919/1000\n",
      "1/1 - 8s - loss: 1.7476 - accuracy: 0.3750 - val_loss: 12.7721 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 920/1000\n",
      "1/1 - 8s - loss: 1.7650 - accuracy: 0.4250 - val_loss: 12.7076 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 921/1000\n",
      "1/1 - 8s - loss: 1.6215 - accuracy: 0.4250 - val_loss: 12.7445 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 922/1000\n",
      "1/1 - 8s - loss: 1.2300 - accuracy: 0.5500 - val_loss: 12.8435 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 923/1000\n",
      "1/1 - 8s - loss: 1.3444 - accuracy: 0.5500 - val_loss: 13.2329 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 924/1000\n",
      "1/1 - 8s - loss: 1.3574 - accuracy: 0.5250 - val_loss: 13.7308 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 925/1000\n",
      "1/1 - 8s - loss: 1.5821 - accuracy: 0.4750 - val_loss: 14.2733 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 926/1000\n",
      "1/1 - 7s - loss: 1.7058 - accuracy: 0.4250 - val_loss: 14.6887 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 927/1000\n",
      "1/1 - 8s - loss: 1.6174 - accuracy: 0.3750 - val_loss: 14.9793 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 928/1000\n",
      "1/1 - 8s - loss: 1.4251 - accuracy: 0.5000 - val_loss: 15.1318 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 929/1000\n",
      "1/1 - 8s - loss: 1.7471 - accuracy: 0.3500 - val_loss: 15.1084 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 930/1000\n",
      "1/1 - 8s - loss: 1.8985 - accuracy: 0.3000 - val_loss: 14.9328 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 931/1000\n",
      "1/1 - 8s - loss: 1.8250 - accuracy: 0.3000 - val_loss: 14.4399 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 932/1000\n",
      "1/1 - 8s - loss: 1.4406 - accuracy: 0.4250 - val_loss: 13.8788 - val_accuracy: 0.1250 - 8s/epoch - 8s/step\n",
      "Epoch 933/1000\n",
      "1/1 - 7s - loss: 1.4205 - accuracy: 0.4500 - val_loss: 13.2641 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 934/1000\n",
      "1/1 - 7s - loss: 1.8601 - accuracy: 0.3250 - val_loss: 12.7491 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 935/1000\n",
      "1/1 - 7s - loss: 1.6638 - accuracy: 0.4000 - val_loss: 12.3037 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 936/1000\n",
      "1/1 - 8s - loss: 1.5513 - accuracy: 0.4750 - val_loss: 11.6778 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 937/1000\n",
      "1/1 - 8s - loss: 1.1258 - accuracy: 0.6250 - val_loss: 11.2227 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 938/1000\n",
      "1/1 - 8s - loss: 1.4783 - accuracy: 0.5250 - val_loss: 11.0217 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 939/1000\n",
      "1/1 - 8s - loss: 1.7744 - accuracy: 0.4250 - val_loss: 11.1766 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 940/1000\n",
      "1/1 - 8s - loss: 1.3537 - accuracy: 0.5250 - val_loss: 11.5979 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 941/1000\n",
      "1/1 - 7s - loss: 1.4187 - accuracy: 0.5500 - val_loss: 12.3426 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 942/1000\n",
      "1/1 - 8s - loss: 1.8762 - accuracy: 0.3000 - val_loss: 13.0490 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 943/1000\n",
      "1/1 - 7s - loss: 1.2562 - accuracy: 0.5000 - val_loss: 13.8114 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 944/1000\n",
      "1/1 - 8s - loss: 1.4401 - accuracy: 0.4500 - val_loss: 14.3974 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 945/1000\n",
      "1/1 - 7s - loss: 1.4820 - accuracy: 0.4000 - val_loss: 14.7557 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 946/1000\n",
      "1/1 - 7s - loss: 1.4351 - accuracy: 0.5000 - val_loss: 14.9921 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 947/1000\n",
      "1/1 - 7s - loss: 1.5884 - accuracy: 0.4250 - val_loss: 14.7689 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 948/1000\n",
      "1/1 - 8s - loss: 1.4513 - accuracy: 0.4750 - val_loss: 14.4780 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 949/1000\n",
      "1/1 - 8s - loss: 1.5205 - accuracy: 0.3750 - val_loss: 14.2041 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 950/1000\n",
      "1/1 - 7s - loss: 1.3585 - accuracy: 0.4750 - val_loss: 13.9078 - val_accuracy: 0.1000 - 7s/epoch - 7s/step\n",
      "Epoch 951/1000\n",
      "1/1 - 8s - loss: 1.7342 - accuracy: 0.4750 - val_loss: 13.6857 - val_accuracy: 0.1000 - 8s/epoch - 8s/step\n",
      "Epoch 952/1000\n",
      "1/1 - 7s - loss: 1.6959 - accuracy: 0.4250 - val_loss: 13.4054 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 953/1000\n",
      "1/1 - 8s - loss: 1.4449 - accuracy: 0.4500 - val_loss: 13.1138 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 954/1000\n",
      "1/1 - 8s - loss: 1.8047 - accuracy: 0.3250 - val_loss: 12.8022 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 955/1000\n",
      "1/1 - 8s - loss: 1.3030 - accuracy: 0.5500 - val_loss: 12.5577 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 956/1000\n",
      "1/1 - 7s - loss: 1.6320 - accuracy: 0.4500 - val_loss: 12.3436 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 957/1000\n",
      "1/1 - 8s - loss: 1.6553 - accuracy: 0.4500 - val_loss: 12.2183 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 958/1000\n",
      "1/1 - 7s - loss: 1.7661 - accuracy: 0.3750 - val_loss: 12.1684 - val_accuracy: 0.0750 - 7s/epoch - 7s/step\n",
      "Epoch 959/1000\n",
      "1/1 - 8s - loss: 1.7091 - accuracy: 0.4500 - val_loss: 13.0925 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 960/1000\n",
      "1/1 - 7s - loss: 1.3074 - accuracy: 0.5750 - val_loss: 14.3556 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 961/1000\n",
      "1/1 - 8s - loss: 1.6362 - accuracy: 0.4000 - val_loss: 15.7099 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "1/1 - 8s - loss: 1.5553 - accuracy: 0.4250 - val_loss: 16.8600 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 963/1000\n",
      "1/1 - 8s - loss: 1.5801 - accuracy: 0.4750 - val_loss: 17.8147 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 964/1000\n",
      "1/1 - 8s - loss: 1.8395 - accuracy: 0.3750 - val_loss: 18.0735 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 965/1000\n",
      "1/1 - 8s - loss: 1.6659 - accuracy: 0.4250 - val_loss: 16.7507 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 966/1000\n",
      "1/1 - 8s - loss: 1.4133 - accuracy: 0.4250 - val_loss: 15.4228 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 967/1000\n",
      "1/1 - 8s - loss: 1.6172 - accuracy: 0.4750 - val_loss: 14.2668 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 968/1000\n",
      "1/1 - 8s - loss: 1.3052 - accuracy: 0.5500 - val_loss: 13.4409 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 969/1000\n",
      "1/1 - 8s - loss: 1.4751 - accuracy: 0.4250 - val_loss: 12.8019 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 970/1000\n",
      "1/1 - 8s - loss: 1.5627 - accuracy: 0.5500 - val_loss: 12.3372 - val_accuracy: 0.0750 - 8s/epoch - 8s/step\n",
      "Epoch 971/1000\n",
      "1/1 - 8s - loss: 1.5913 - accuracy: 0.4250 - val_loss: 12.0164 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 972/1000\n",
      "1/1 - 8s - loss: 1.6624 - accuracy: 0.4750 - val_loss: 11.8798 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 973/1000\n",
      "1/1 - 8s - loss: 1.4950 - accuracy: 0.4750 - val_loss: 11.7695 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 974/1000\n",
      "1/1 - 9s - loss: 1.6231 - accuracy: 0.4000 - val_loss: 11.5823 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 975/1000\n",
      "1/1 - 9s - loss: 1.5928 - accuracy: 0.4500 - val_loss: 11.4587 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 976/1000\n",
      "1/1 - 9s - loss: 1.3918 - accuracy: 0.6000 - val_loss: 11.4455 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 977/1000\n",
      "1/1 - 9s - loss: 1.6433 - accuracy: 0.5000 - val_loss: 11.4315 - val_accuracy: 0.0500 - 9s/epoch - 9s/step\n",
      "Epoch 978/1000\n",
      "1/1 - 8s - loss: 1.3346 - accuracy: 0.5000 - val_loss: 11.4782 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 979/1000\n",
      "1/1 - 8s - loss: 1.6282 - accuracy: 0.4500 - val_loss: 11.6246 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 980/1000\n",
      "1/1 - 7s - loss: 1.5190 - accuracy: 0.3500 - val_loss: 11.8236 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 981/1000\n",
      "1/1 - 8s - loss: 1.6482 - accuracy: 0.4750 - val_loss: 12.0486 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 982/1000\n",
      "1/1 - 8s - loss: 1.7336 - accuracy: 0.4500 - val_loss: 12.3356 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 983/1000\n",
      "1/1 - 8s - loss: 1.8194 - accuracy: 0.3500 - val_loss: 12.4479 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 984/1000\n",
      "1/1 - 7s - loss: 1.7201 - accuracy: 0.4250 - val_loss: 12.5056 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 985/1000\n",
      "1/1 - 8s - loss: 1.4975 - accuracy: 0.4500 - val_loss: 12.5301 - val_accuracy: 0.0500 - 8s/epoch - 8s/step\n",
      "Epoch 986/1000\n",
      "1/1 - 7s - loss: 1.4039 - accuracy: 0.5000 - val_loss: 12.4803 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 987/1000\n",
      "1/1 - 7s - loss: 1.5815 - accuracy: 0.4750 - val_loss: 12.4424 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 988/1000\n",
      "1/1 - 7s - loss: 1.7162 - accuracy: 0.4250 - val_loss: 12.5615 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 989/1000\n",
      "1/1 - 7s - loss: 1.7328 - accuracy: 0.3750 - val_loss: 12.6650 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 990/1000\n",
      "1/1 - 7s - loss: 1.5502 - accuracy: 0.4750 - val_loss: 12.7573 - val_accuracy: 0.0500 - 7s/epoch - 7s/step\n",
      "Epoch 991/1000\n",
      "1/1 - 8s - loss: 1.7252 - accuracy: 0.3750 - val_loss: 12.7707 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 992/1000\n",
      "1/1 - 7s - loss: 1.4757 - accuracy: 0.5250 - val_loss: 12.7210 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 993/1000\n",
      "1/1 - 7s - loss: 1.6285 - accuracy: 0.3500 - val_loss: 12.7635 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 994/1000\n",
      "1/1 - 7s - loss: 1.1473 - accuracy: 0.6500 - val_loss: 12.9245 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 995/1000\n",
      "1/1 - 7s - loss: 1.2883 - accuracy: 0.5750 - val_loss: 13.0910 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 996/1000\n",
      "1/1 - 7s - loss: 1.5383 - accuracy: 0.4000 - val_loss: 13.1301 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 997/1000\n",
      "1/1 - 7s - loss: 1.3644 - accuracy: 0.5250 - val_loss: 13.1772 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 998/1000\n",
      "1/1 - 8s - loss: 1.4214 - accuracy: 0.5500 - val_loss: 13.2287 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n",
      "Epoch 999/1000\n",
      "1/1 - 7s - loss: 1.7492 - accuracy: 0.4250 - val_loss: 13.3115 - val_accuracy: 0.0250 - 7s/epoch - 7s/step\n",
      "Epoch 1000/1000\n",
      "1/1 - 8s - loss: 1.4821 - accuracy: 0.4750 - val_loss: 13.3707 - val_accuracy: 0.0250 - 8s/epoch - 8s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from RMDL import text_feature_extraction as txt\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data[:40]\n",
    "X_test = newsgroups_test.data[:40]\n",
    "y_train = newsgroups_train.target[:40]\n",
    "y_test = newsgroups_test.target[:40]\n",
    "\n",
    "\n",
    "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test)\n",
    "\n",
    "\n",
    "model_CNN = Build_Model_CNN_Text(word_index,embeddings_index, 20)\n",
    "\n",
    "\n",
    "model_CNN.summary()\n",
    "\n",
    "model_CNN.fit(X_train_Glove, y_train,\n",
    "                              validation_data=(X_test_Glove, y_test),\n",
    "                              epochs=1000,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)\n",
    "\n",
    "predicted = model_CNN.predict(X_test_Glove)\n",
    "\n",
    "predicted = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "XldCcrf5nlqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.50      0.33      0.40         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.03        40\n",
      "   macro avg       0.03      0.02      0.02        40\n",
      "weighted avg       0.04      0.03      0.03        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
