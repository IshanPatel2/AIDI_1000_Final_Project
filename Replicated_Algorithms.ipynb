{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d8915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=10, micro=9, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\Glove'\n",
    "\n",
    "# url of the binary data\n",
    "\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract(data='Wikipedia'):\n",
    "    \"\"\"\n",
    "    Download and extract the GloVe\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if data=='Wikipedia':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    elif data=='Common_Crawl_840B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip'\n",
    "    elif data=='Common_Crawl_42B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip'\n",
    "    elif data=='Twitter':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip'\n",
    "    else:\n",
    "        print(\"prameter should be Twitter, Common_Crawl_42B, Common_Crawl_840B, or Wikipedia\")\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    print(filepath)\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath)#, reporthook=_progress)\n",
    "\n",
    "\n",
    "        zip_ref = zipfile.ZipFile(filepath, 'r')\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "        zip_ref.close()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f4c61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=10, micro=9, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\data_WOS'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'http://kowsari.net/WebOfScience.tar.gz'\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the WOS datasets\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "\n",
    "        print('Downloaded', filename)\n",
    "\n",
    "        tarfile.open(filepath, 'r').extractall(dest_directory)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63124e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       319\n",
      "           1       0.76      0.80      0.78       389\n",
      "           2       0.77      0.73      0.75       394\n",
      "           3       0.71      0.76      0.74       392\n",
      "           4       0.84      0.86      0.85       385\n",
      "           5       0.87      0.76      0.81       395\n",
      "           6       0.83      0.91      0.87       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.95      0.95      0.95       398\n",
      "           9       0.92      0.95      0.93       397\n",
      "          10       0.96      0.98      0.97       399\n",
      "          11       0.93      0.94      0.93       396\n",
      "          12       0.81      0.79      0.80       393\n",
      "          13       0.90      0.87      0.88       396\n",
      "          14       0.90      0.93      0.92       394\n",
      "          15       0.84      0.93      0.88       398\n",
      "          16       0.75      0.92      0.82       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.82      0.62      0.71       310\n",
      "          19       0.75      0.61      0.68       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.85      0.85      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02746a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       319\n",
      "           1       0.57      0.71      0.63       389\n",
      "           2       0.66      0.74      0.70       394\n",
      "           3       0.67      0.64      0.65       392\n",
      "           4       0.69      0.76      0.72       385\n",
      "           5       0.77      0.70      0.73       395\n",
      "           6       0.74      0.92      0.82       390\n",
      "           7       0.82      0.79      0.81       396\n",
      "           8       0.91      0.91      0.91       398\n",
      "           9       0.81      0.91      0.86       397\n",
      "          10       0.90      0.92      0.91       399\n",
      "          11       0.86      0.93      0.89       396\n",
      "          12       0.68      0.51      0.58       393\n",
      "          13       0.84      0.64      0.73       396\n",
      "          14       0.83      0.89      0.86       394\n",
      "          15       0.71      0.92      0.80       398\n",
      "          16       0.67      0.87      0.75       364\n",
      "          17       0.95      0.81      0.88       376\n",
      "          18       0.86      0.49      0.62       310\n",
      "          19       0.80      0.33      0.47       251\n",
      "\n",
      "    accuracy                           0.76      7532\n",
      "   macro avg       0.77      0.75      0.75      7532\n",
      "weighted avg       0.77      0.76      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e454e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.76      0.55       319\n",
      "           1       0.50      0.61      0.55       389\n",
      "           2       0.56      0.57      0.57       394\n",
      "           3       0.53      0.58      0.56       392\n",
      "           4       0.59      0.56      0.57       385\n",
      "           5       0.69      0.60      0.64       395\n",
      "           6       0.58      0.45      0.51       390\n",
      "           7       0.75      0.69      0.72       396\n",
      "           8       0.84      0.81      0.82       398\n",
      "           9       0.77      0.72      0.74       397\n",
      "          10       0.85      0.84      0.84       399\n",
      "          11       0.76      0.84      0.80       396\n",
      "          12       0.70      0.50      0.58       393\n",
      "          13       0.82      0.49      0.62       396\n",
      "          14       0.79      0.76      0.78       394\n",
      "          15       0.75      0.76      0.76       398\n",
      "          16       0.70      0.73      0.72       364\n",
      "          17       0.62      0.76      0.69       376\n",
      "          18       0.55      0.61      0.58       310\n",
      "          19       0.56      0.49      0.52       251\n",
      "\n",
      "    accuracy                           0.66      7532\n",
      "   macro avg       0.67      0.66      0.65      7532\n",
      "weighted avg       0.67      0.66      0.66      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kNeigh\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cceadd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       319\n",
      "           1       0.43      0.43      0.43       389\n",
      "           2       0.53      0.57      0.55       394\n",
      "           3       0.44      0.41      0.42       392\n",
      "           4       0.52      0.56      0.54       385\n",
      "           5       0.51      0.48      0.50       395\n",
      "           6       0.64      0.73      0.69       390\n",
      "           7       0.60      0.60      0.60       396\n",
      "           8       0.71      0.74      0.73       398\n",
      "           9       0.53      0.56      0.55       397\n",
      "          10       0.68      0.67      0.68       399\n",
      "          11       0.76      0.70      0.73       396\n",
      "          12       0.35      0.33      0.34       393\n",
      "          13       0.48      0.43      0.45       396\n",
      "          14       0.68      0.62      0.65       394\n",
      "          15       0.68      0.70      0.69       398\n",
      "          16       0.52      0.61      0.56       364\n",
      "          17       0.77      0.62      0.69       376\n",
      "          18       0.37      0.37      0.37       310\n",
      "          19       0.32      0.33      0.33       251\n",
      "\n",
      "    accuracy                           0.55      7532\n",
      "   macro avg       0.55      0.55      0.55      7532\n",
      "weighted avg       0.56      0.55      0.55      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', tree.DecisionTreeClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b62ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 75000 features\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               38400512  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39461396 (150.53 MB)\n",
      "Trainable params: 39461396 (150.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "89/89 - 59s - loss: 2.8420 - accuracy: 0.0917 - val_loss: 2.3243 - val_accuracy: 0.2869 - 59s/epoch - 666ms/step\n",
      "Epoch 2/10\n",
      "89/89 - 36s - loss: 1.6328 - accuracy: 0.4042 - val_loss: 1.1940 - val_accuracy: 0.5645 - 36s/epoch - 408ms/step\n",
      "Epoch 3/10\n",
      "89/89 - 38s - loss: 0.8954 - accuracy: 0.6531 - val_loss: 0.9524 - val_accuracy: 0.7031 - 38s/epoch - 426ms/step\n",
      "Epoch 4/10\n",
      "89/89 - 38s - loss: 0.4488 - accuracy: 0.8328 - val_loss: 0.8914 - val_accuracy: 0.7650 - 38s/epoch - 431ms/step\n",
      "Epoch 5/10\n",
      "89/89 - 39s - loss: 0.2440 - accuracy: 0.9179 - val_loss: 0.8888 - val_accuracy: 0.7906 - 39s/epoch - 437ms/step\n",
      "Epoch 6/10\n",
      "89/89 - 39s - loss: 0.1569 - accuracy: 0.9524 - val_loss: 0.8788 - val_accuracy: 0.7991 - 39s/epoch - 433ms/step\n",
      "Epoch 7/10\n",
      "89/89 - 38s - loss: 0.0944 - accuracy: 0.9719 - val_loss: 1.0229 - val_accuracy: 0.7935 - 38s/epoch - 430ms/step\n",
      "Epoch 8/10\n",
      "89/89 - 38s - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.9824 - val_accuracy: 0.8010 - 38s/epoch - 426ms/step\n",
      "Epoch 9/10\n",
      "89/89 - 38s - loss: 0.0579 - accuracy: 0.9835 - val_loss: 0.9811 - val_accuracy: 0.8054 - 38s/epoch - 427ms/step\n",
      "Epoch 10/10\n",
      "89/89 - 38s - loss: 0.0518 - accuracy: 0.9874 - val_loss: 1.0089 - val_accuracy: 0.8063 - 38s/epoch - 430ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e6002e15a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN\n",
    "from keras.layers import  Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def TFIDF(X_train, X_test,MAX_NB_WORDS=75000):\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
    "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer_x.transform(X_test).toarray()\n",
    "    print(\"tf-idf with\",str(np.array(X_train).shape[1]),\"features\")\n",
    "    return (X_train,X_test)\n",
    "\n",
    "\n",
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.5):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "X_train_tfidf,X_test_tfidf = TFIDF(X_train,X_test)\n",
    "\n",
    "\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 20)\n",
    "model_DNN.summary()\n",
    "exit(1)\n",
    "model_DNN.fit(X_train_tfidf, y_train,\n",
    "                              validation_data=(X_test_tfidf, y_test),\n",
    "                              epochs=10,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac41572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63       319\n",
      "           1       0.81      0.65      0.72       389\n",
      "           2       0.82      0.65      0.73       394\n",
      "           3       0.67      0.78      0.72       392\n",
      "           4       0.86      0.77      0.81       385\n",
      "           5       0.89      0.75      0.82       395\n",
      "           6       0.93      0.69      0.80       390\n",
      "           7       0.85      0.92      0.88       396\n",
      "           8       0.94      0.93      0.93       398\n",
      "           9       0.92      0.90      0.91       397\n",
      "          10       0.89      0.97      0.93       399\n",
      "          11       0.59      0.97      0.74       396\n",
      "          12       0.84      0.60      0.70       393\n",
      "          13       0.92      0.74      0.82       396\n",
      "          14       0.84      0.89      0.87       394\n",
      "          15       0.44      0.98      0.61       398\n",
      "          16       0.64      0.94      0.76       364\n",
      "          17       0.93      0.91      0.92       376\n",
      "          18       0.96      0.42      0.58       310\n",
      "          19       0.97      0.14      0.24       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.83      0.76      0.76      7532\n",
      "weighted avg       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb34f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
